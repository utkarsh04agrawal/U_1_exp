{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/utkarshagrawal/Documents/Postdoc/U_1_exp/Quantinum/Weak measurements\n"
     ]
    }
   ],
   "source": [
    "from pytket.circuit import Circuit, fresh_symbol\n",
    "from pytket.circuit.display import render_circuit_jupyter\n",
    "from pytket.extensions.quantinuum import QuantinuumBackend\n",
    "import matplotlib.pyplot as pl\n",
    "\n",
    "import os\n",
    "print(os.getcwd())\n",
    "\n",
    "from pytket.extensions.qiskit import qiskit_to_tk, AerBackend\n",
    "from pytket.backends.backendresult import BackendResult\n",
    "\n",
    "import qiskit as qk\n",
    "\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "which_machine = 'emulator'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "QuantinuumAPIError",
     "evalue": "HTTP error attempting: Login.\n\nServer Response: {'error': {'code': 1, 'text': 'An error occurred (InvalidParameterException) when calling the InitiateAuth operation: Missing required parameter USERNAME'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mQuantinuumAPIError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m backend \u001b[39m=\u001b[39m QuantinuumBackend(machine)\n\u001b[1;32m      7\u001b[0m \u001b[39m# backend.login()\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[39mprint\u001b[39m(machine, \u001b[39m\"\u001b[39m\u001b[39mstatus:\u001b[39m\u001b[39m\"\u001b[39m, backend\u001b[39m.\u001b[39;49mdevice_state(device_name\u001b[39m=\u001b[39;49mmachine))\n",
      "File \u001b[0;32m~/Documents/Postdoc/U_1_exp/Quantinum/qtuum/lib/python3.9/site-packages/pytket/extensions/quantinuum/backends/quantinuum.py:321\u001b[0m, in \u001b[0;36mQuantinuumBackend.device_state\u001b[0;34m(cls, device_name, api_handler)\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    302\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdevice_state\u001b[39m(\n\u001b[1;32m    303\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[1;32m    304\u001b[0m     device_name: \u001b[39mstr\u001b[39m,\n\u001b[1;32m    305\u001b[0m     api_handler: QuantinuumAPI \u001b[39m=\u001b[39m DEFAULT_API_HANDLER,\n\u001b[1;32m    306\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[1;32m    307\u001b[0m     \u001b[39m\"\"\"Check the status of a device.\u001b[39;00m\n\u001b[1;32m    308\u001b[0m \n\u001b[1;32m    309\u001b[0m \u001b[39m    >>> QuantinuumBackend.device_state('H1') # e.g. \"online\"\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[39m    :rtype: str\u001b[39;00m\n\u001b[1;32m    318\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     res \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39mget(\n\u001b[1;32m    320\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mapi_handler\u001b[39m.\u001b[39murl\u001b[39m}\u001b[39;00m\u001b[39mmachine/\u001b[39m\u001b[39m{\u001b[39;00mdevice_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m--> 321\u001b[0m         headers\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mAuthorization\u001b[39m\u001b[39m\"\u001b[39m: api_handler\u001b[39m.\u001b[39;49mlogin()},\n\u001b[1;32m    322\u001b[0m     )\n\u001b[1;32m    323\u001b[0m     api_handler\u001b[39m.\u001b[39m_response_check(res, \u001b[39m\"\u001b[39m\u001b[39mget machine status\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    324\u001b[0m     jr \u001b[39m=\u001b[39m res\u001b[39m.\u001b[39mjson()\n",
      "File \u001b[0;32m~/Documents/Postdoc/U_1_exp/Quantinum/qtuum/lib/python3.9/site-packages/pytket/extensions/quantinuum/backends/api_wrappers.py:274\u001b[0m, in \u001b[0;36mQuantinuumAPI.login\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    272\u001b[0m refresh_token \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cred_store\u001b[39m.\u001b[39mrefresh_token\n\u001b[1;32m    273\u001b[0m \u001b[39mif\u001b[39;00m refresh_token \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 274\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfull_login()\n\u001b[1;32m    275\u001b[0m     refresh_token \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cred_store\u001b[39m.\u001b[39mrefresh_token\n\u001b[1;32m    277\u001b[0m \u001b[39mif\u001b[39;00m refresh_token \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/Postdoc/U_1_exp/Quantinum/qtuum/lib/python3.9/site-packages/pytket/extensions/quantinuum/backends/api_wrappers.py:260\u001b[0m, in \u001b[0;36mQuantinuumAPI.full_login\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[39m\"\"\"Ask for user credentials from std input and update JWT tokens\"\"\"\u001b[39;00m\n\u001b[1;32m    259\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprovider \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 260\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_request_tokens(\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_credentials())\n\u001b[1;32m    261\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    262\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_request_tokens_federated()\n",
      "File \u001b[0;32m~/Documents/Postdoc/U_1_exp/Quantinum/qtuum/lib/python3.9/site-packages/pytket/extensions/quantinuum/backends/api_wrappers.py:179\u001b[0m, in \u001b[0;36mQuantinuumAPI._request_tokens\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[39m# resend request to login\u001b[39;00m\n\u001b[1;32m    174\u001b[0m         response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msession\u001b[39m.\u001b[39mpost(\n\u001b[1;32m    175\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39murl\u001b[39m}\u001b[39;00m\u001b[39mlogin\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    176\u001b[0m             json\u001b[39m.\u001b[39mdumps(body),\n\u001b[1;32m    177\u001b[0m         )\n\u001b[0;32m--> 179\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_response_check(response, \u001b[39m\"\u001b[39;49m\u001b[39mLogin\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m    180\u001b[0m resp_dict \u001b[39m=\u001b[39m response\u001b[39m.\u001b[39mjson()\n\u001b[1;32m    181\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cred_store\u001b[39m.\u001b[39msave_tokens(\n\u001b[1;32m    182\u001b[0m     resp_dict[\u001b[39m\"\u001b[39m\u001b[39mid-token\u001b[39m\u001b[39m\"\u001b[39m], resp_dict[\u001b[39m\"\u001b[39m\u001b[39mrefresh-token\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    183\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/Postdoc/U_1_exp/Quantinum/qtuum/lib/python3.9/site-packages/pytket/extensions/quantinuum/backends/api_wrappers.py:320\u001b[0m, in \u001b[0;36mQuantinuumAPI._response_check\u001b[0;34m(self, res, description)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[39melif\u001b[39;00m res\u001b[39m.\u001b[39mstatus_code \u001b[39m!=\u001b[39m HTTPStatus\u001b[39m.\u001b[39mOK:\n\u001b[1;32m    319\u001b[0m     jr \u001b[39m=\u001b[39m res\u001b[39m.\u001b[39mjson()\n\u001b[0;32m--> 320\u001b[0m     \u001b[39mraise\u001b[39;00m QuantinuumAPIError(\n\u001b[1;32m    321\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mHTTP error attempting: \u001b[39m\u001b[39m{\u001b[39;00mdescription\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39mServer Response: \u001b[39m\u001b[39m{\u001b[39;00mjr\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n",
      "\u001b[0;31mQuantinuumAPIError\u001b[0m: HTTP error attempting: Login.\n\nServer Response: {'error': {'code': 1, 'text': 'An error occurred (InvalidParameterException) when calling the InitiateAuth operation: Missing required parameter USERNAME'}}"
     ]
    }
   ],
   "source": [
    "\n",
    "if which_machine == 'emulator':\n",
    "    machine = 'H1-1E'\n",
    "elif which_machine == 'hardware':\n",
    "    machine = 'H1-1'\n",
    "\n",
    "backend = QuantinuumBackend(machine)\n",
    "# backend.login()\n",
    "\n",
    "print(machine, \"status:\", backend.device_state(device_name=machine))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'data/compiled_circuits_multiple_ancillas'\n",
    "\n",
    "# For circuits with scrambling time = 2\n",
    "# file = 'data/compiled_circuits_multiple_ancillas_t_scram=2'\n",
    "\n",
    "with open('data/compiled_circuits_multiple_ancillas','rb') as f:\n",
    "    compiled_circuits = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(14, 14, 0.253, 7),\n",
       " (10, 10, 0.306, 4),\n",
       " (8, 8, 0.571, 4),\n",
       " (14, 14, 0.412, 7),\n",
       " (8, 8, 0.783, 4),\n",
       " (10, 10, 0.624, 5),\n",
       " (10, 10, 0.465, 4),\n",
       " (12, 12, 0.942, 5),\n",
       " (8, 8, 0.942, 3),\n",
       " (10, 10, 0.2, 4),\n",
       " (12, 12, 0.2, 5),\n",
       " (12, 12, 0.624, 6),\n",
       " (10, 10, 0.571, 4),\n",
       " (8, 8, 0.306, 4),\n",
       " (14, 14, 0.889, 6),\n",
       " (14, 14, 0.359, 6),\n",
       " (14, 14, 0.677, 6),\n",
       " (10, 10, 0.783, 4),\n",
       " (14, 14, 0.836, 6),\n",
       " (8, 8, 0.465, 4),\n",
       " (14, 14, 0.518, 6),\n",
       " (10, 10, 0.677, 5),\n",
       " (10, 10, 0.518, 5),\n",
       " (8, 8, 0.412, 4),\n",
       " (10, 10, 0.836, 5),\n",
       " (14, 14, 0.783, 7),\n",
       " (14, 14, 0.571, 7),\n",
       " (12, 12, 0.2, 6),\n",
       " (10, 10, 0.359, 5),\n",
       " (10, 10, 0.889, 5),\n",
       " (8, 8, 0.253, 4),\n",
       " (14, 14, 0.2, 6),\n",
       " (14, 14, 0.465, 7),\n",
       " (14, 14, 0.624, 6),\n",
       " (10, 10, 0.412, 4),\n",
       " (12, 12, 0.359, 6),\n",
       " (12, 12, 0.889, 6),\n",
       " (12, 12, 0.677, 6),\n",
       " (10, 10, 0.253, 4),\n",
       " (14, 14, 0.306, 7),\n",
       " (6, 6, 0.942, 3),\n",
       " (12, 12, 0.518, 6),\n",
       " (12, 12, 0.836, 6),\n",
       " (14, 14, 0.889, 7),\n",
       " (14, 14, 0.359, 7),\n",
       " (8, 8, 0.73, 4),\n",
       " (10, 10, 0.571, 5),\n",
       " (12, 12, 0.465, 6),\n",
       " (14, 14, 0.518, 7),\n",
       " (10, 10, 0.783, 5),\n",
       " (8, 8, 0.624, 4),\n",
       " (14, 14, 0.836, 7),\n",
       " (14, 14, 0.677, 7),\n",
       " (12, 12, 0.73, 5),\n",
       " (12, 12, 0.306, 6),\n",
       " (12, 12, 0.73, 6),\n",
       " (12, 12, 0.783, 6),\n",
       " (10, 10, 0.73, 5),\n",
       " (10, 10, 0.306, 5),\n",
       " (14, 14, 0.253, 6),\n",
       " (10, 10, 0.73, 4),\n",
       " (12, 12, 0.571, 6),\n",
       " (8, 8, 0.2, 4),\n",
       " (10, 10, 0.624, 4),\n",
       " (10, 10, 0.465, 5),\n",
       " (14, 14, 0.412, 6),\n",
       " (8, 8, 0.677, 4),\n",
       " (6, 6, 0.2, 3),\n",
       " (10, 10, 0.412, 5),\n",
       " (8, 8, 0.836, 4),\n",
       " (14, 14, 0.465, 6),\n",
       " (14, 14, 0.624, 7),\n",
       " (8, 8, 0.518, 4),\n",
       " (14, 14, 0.306, 6),\n",
       " (10, 10, 0.253, 5),\n",
       " (6, 6, 0.942, 2),\n",
       " (8, 8, 0.359, 4),\n",
       " (8, 8, 0.889, 4),\n",
       " (10, 10, 0.836, 4),\n",
       " (14, 14, 0.783, 6),\n",
       " (10, 10, 0.518, 4),\n",
       " (8, 8, 0.73, 3),\n",
       " (12, 12, 0.253, 6),\n",
       " (14, 14, 0.73, 7),\n",
       " (10, 10, 0.677, 4),\n",
       " (10, 10, 0.359, 4),\n",
       " (10, 10, 0.889, 4),\n",
       " (14, 14, 0.73, 6),\n",
       " (12, 12, 0.412, 6),\n",
       " (14, 14, 0.571, 6),\n",
       " (8, 8, 0.412, 3),\n",
       " (12, 12, 0.412, 5),\n",
       " (14, 14, 0.942, 7),\n",
       " (6, 6, 0.306, 3),\n",
       " (6, 6, 0.2, 2),\n",
       " (8, 8, 0.253, 3),\n",
       " (12, 12, 0.253, 5),\n",
       " (6, 6, 0.624, 2),\n",
       " (6, 6, 0.465, 3),\n",
       " (6, 6, 0.73, 3),\n",
       " (6, 6, 0.571, 3),\n",
       " (6, 6, 0.783, 3),\n",
       " (6, 6, 0.73, 2),\n",
       " (6, 6, 0.836, 2),\n",
       " (8, 8, 0.571, 3),\n",
       " (6, 6, 0.518, 2),\n",
       " (12, 12, 0.571, 5),\n",
       " (6, 6, 0.677, 2),\n",
       " (8, 8, 0.942, 4),\n",
       " (6, 6, 0.359, 2),\n",
       " (12, 12, 0.783, 5),\n",
       " (6, 6, 0.889, 2),\n",
       " (8, 8, 0.783, 3),\n",
       " (8, 8, 0.306, 3),\n",
       " (6, 6, 0.412, 3),\n",
       " (12, 12, 0.306, 5),\n",
       " (8, 8, 0.465, 3),\n",
       " (6, 6, 0.253, 3),\n",
       " (10, 10, 0.942, 4),\n",
       " (12, 12, 0.465, 5),\n",
       " (8, 8, 0.836, 3),\n",
       " (12, 12, 0.677, 5),\n",
       " (8, 8, 0.2, 3),\n",
       " (8, 8, 0.518, 3),\n",
       " (6, 6, 0.571, 2),\n",
       " (12, 12, 0.518, 5),\n",
       " (12, 12, 0.836, 5),\n",
       " (8, 8, 0.677, 3),\n",
       " (8, 8, 0.889, 3),\n",
       " (8, 8, 0.359, 3),\n",
       " (6, 6, 0.783, 2),\n",
       " (12, 12, 0.359, 5),\n",
       " (12, 12, 0.889, 5),\n",
       " (14, 14, 0.942, 6),\n",
       " (6, 6, 0.306, 2),\n",
       " (14, 14, 0.2, 7),\n",
       " (6, 6, 0.624, 3),\n",
       " (6, 6, 0.465, 2),\n",
       " (6, 6, 0.412, 2),\n",
       " (10, 10, 0.2, 5),\n",
       " (12, 12, 0.624, 5),\n",
       " (6, 6, 0.253, 2),\n",
       " (10, 10, 0.942, 5),\n",
       " (8, 8, 0.624, 3),\n",
       " (6, 6, 0.677, 3),\n",
       " (12, 12, 0.942, 6),\n",
       " (6, 6, 0.518, 3),\n",
       " (6, 6, 0.836, 3),\n",
       " (6, 6, 0.359, 3),\n",
       " (6, 6, 0.889, 3)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[param for param in compiled_circuits]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For $t_scram=5$ we used following values for p \n",
    "```python\n",
    "    p_list = np.round(np.linspace(0.2,0.6*np.pi/2,15),3)[:]\n",
    "```\n",
    " \n",
    "    \n",
    "\n",
    "For $t_{scram}=2$ we used following values\n",
    "```python\n",
    "    p_list = np.round(np.linspace(0.2*np.pi/2,0.8*np.pi/2,15),3)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_shots = 200\n",
    "# p_list = [0.571,0.624,0.677,0.73,0.783][:]\n",
    "p_list = [0.412,0.518,0.624,0.73,0.836] # this is for t_scram=2\n",
    "L_list = [8,12,16][:]\n",
    "\n",
    "def run_emulator():\n",
    "    count = 0\n",
    "    handle_dict = {}\n",
    "    for param,circ in compiled_circuits.items():\n",
    "        L,depth,p,Q = param\n",
    "        if L not in L_list:\n",
    "            continue\n",
    "        if p not in p_list:\n",
    "            continue\n",
    "        if count == 0:\n",
    "            first_batch = backend.process_circuit(circuit=circ, n_shots=n_shots)\n",
    "            handle_dict[param] = first_batch\n",
    "        else:\n",
    "            new_batch = backend.process_circuit(circuit=circ, n_shots=n_shots)\n",
    "            handle_dict[param] = new_batch\n",
    "        count += 1\n",
    "    return handle_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "handle_dict = run_emulator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[backend.circuit_status(handle) for handle in handle_dict.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving and loading handle dictionary\n",
    "\n",
    "def save_handle_dict(handle_dict,file_dir):\n",
    "    temp = len(os.listdir(file_dir))\n",
    "    file_dir = file_dir + str(temp+1) +'/'\n",
    "    if not os.path.isdir(file_dir):\n",
    "        os.makedirs(file_dir)\n",
    "    with open(file_dir + 'handle_dict','wb') as f:\n",
    "        pickle.dump(handle_dict,f)\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    df['L'] = []\n",
    "    df['shots'] = []\n",
    "    df['p'] = []\n",
    "    display(df)\n",
    "\n",
    "    number_of_p = len(p_list)\n",
    "    for param in handle_dict:\n",
    "        L,depth,p,Q = param\n",
    "        if Q!= L//2:\n",
    "            continue\n",
    "        temp = pd.DataFrame({'L':[L],'p':[p],'shots':[n_shots]})\n",
    "        df = pd.concat([df,temp],ignore_index=True)\n",
    "\n",
    "    display(df)\n",
    "    df.to_csv(file_dir+'information.csv')\n",
    "\n",
    "def load_handle_dict(file_loc,batch_number):\n",
    "    file_loc = file_loc +str(batch_number)+'/handle_dict'\n",
    "    with open(file_loc,'rb') as f:\n",
    "        handle_dict = pickle.load(f)\n",
    "    return handle_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if which_machine == 'emulator':\n",
    "    file_dir = 'data/emulator_data/emulator_handle/'\n",
    "elif which_machine == 'hardware':\n",
    "    file_dir = 'data/hardware_data/handle_data/'\n",
    "\n",
    "# save_handle_dict(handle_dict,file_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting results from the completed jobs\n",
    "def get_result(handle_dic):\n",
    "    result_dict = {}\n",
    "    for param, handle in handle_dic.items():\n",
    "        result_dict[param] = backend.get_result(handle).to_dict()\n",
    "    return result_dict\n",
    "\n",
    "def save_result_dict(result_dict,file_dir,batch_number):\n",
    "    file_dir = file_dir + str(batch_number) +'/'\n",
    "    file_loc = file_dir + 'result'\n",
    "    with open(file_loc,'wb') as f:\n",
    "        pickle.dump(result_dict,f)\n",
    "\n",
    "def load_result_dict(file_dir,batch_number):\n",
    "\n",
    "    if 'result' not in os.listdir(file_dir):\n",
    "        handle_dict = load_handle_dict(file_dir,batch_number)\n",
    "        result_dict = get_result(handle_dict)\n",
    "        save_result_dict(result_dict,file_dir,batch_number)\n",
    "    else:\n",
    "        with open(file_dir+ str(batch_number)+'/result','rb') as f:\n",
    "            result_dict = pickle.load(f)\n",
    "    return result_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_number = 2\n",
    "\n",
    "result_dict = load_result_dict(file_dir, batch_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get outcome data (to be given as input to the decoder code) from the quantinuum emulator/hardware results\n",
    "\n",
    "### If there is confusion with regards to the outcome data, generate it from scratch for the interested batch numbers. A better data management needs to be thought of.\n",
    "\n",
    "def outcome_from_results(result,L,depth):\n",
    "    # bitlist = result.get_bitlist()\n",
    "    def get_bitlist():\n",
    "        c_bits = [pytket.Bit('') for _ in range(L*depth)]\n",
    "        for i in range(L*depth):\n",
    "            x = i%L\n",
    "            t = i//L\n",
    "            temp = ['c'+str(t),[x]]\n",
    "            c_bits[i] = c_bits[i].from_list(temp)\n",
    "        return c_bits\n",
    "\n",
    "    bitlist = get_bitlist()\n",
    "    measurement_dic = result.get_counts(cbits=bitlist)\n",
    "    # measurement_dic = {measurements in a single shot:number of occurances}\n",
    "\n",
    "    outcome_list = []\n",
    "\n",
    "    for data,N in measurement_dic.items(): # data is measurement outcomes in one shot\n",
    "        data = np.array(data,dtype=int).reshape((depth,L))\n",
    "        data = 2*data - 1\n",
    "        outcome_list.append((data,N))\n",
    "\n",
    "    return outcome_list\n",
    "\n",
    "\n",
    "def get_outcomes(file_dir,batch_number,outcome_filedir):\n",
    "    file_dir = file_dir+str(batch_number)+'/'\n",
    "\n",
    "    if 'outcomes_generated' in os.listdir(file_dir):\n",
    "        return ## outcomes were already generated for this batch\n",
    "\n",
    "\n",
    "    for param, result in result_dict.items():\n",
    "        print(param)\n",
    "        result = BackendResult.from_dict(result)\n",
    "        L,depth,p,Q = param\n",
    "\n",
    "        ## defining output file name\n",
    "        if int(depth/L) == 1:\n",
    "            depth_label = ''\n",
    "        else:\n",
    "            depth_label = \"_depth_ratio=\"+str(int(depth/L))\n",
    "        \n",
    "        outcome_filedir = outcome_filedir + depth_label + '/'\n",
    "        \n",
    "        if not os.path.isdir(outcome_filedir):\n",
    "            os.makedirs(outcome_filedir)\n",
    "        \n",
    "        outcome_file = outcome_filedir + 'L='+str(L)+'_depth='+str(depth)+'_Q='+str(Q)+'_p=' + str(p)+ '_seed='+str(1)\n",
    "        ########\n",
    "\n",
    "        if os.path.isfile(outcome_file):\n",
    "            with open(outcome_file,'rb') as f:\n",
    "                outcomes = pickle.load(f)\n",
    "        else:\n",
    "            outcomes = []\n",
    "\n",
    "        outcomes = []\n",
    "        new_outcomes = outcome_from_results(result,L,depth)\n",
    "        outcomes.extend(new_outcomes)\n",
    "\n",
    "        with open(outcome_file,'wb') as f:\n",
    "            pickle.dump(outcomes,f)\n",
    "\n",
    "    with open(file_dir+'outcomes_generated','wb') as f:\n",
    "        pickle.dump(\"\",f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if which_machine == 'emulator':\n",
    "    outcome_file_dir = 'data/emulator_data/measurement_data_all_qubits_noisy/'\n",
    "elif which_machine == 'hardware':\n",
    "    outcome_file_dir = 'data/hardware_data/measurement_data_all_qubits_noisy/'\n",
    "\n",
    "get_outcomes(file_dir=file_dir,batch_number=batch_number,outcome_filedir=outcome_file_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sep_decoder_2 \n",
    "%reload_ext sep_decoder_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 0.412 4  frac of faulty traj: 0.0  time= 0.14880609512329102\n",
      "8 0.412 3  frac of faulty traj: 0.0  time= 0.1466202735900879\n",
      "8 0.518 4  frac of faulty traj: 0.0  time= 0.14717578887939453\n",
      "8 0.518 3  frac of faulty traj: 0.0  time= 0.14740729331970215\n",
      "8 0.624 4  frac of faulty traj: 0.01  time= 0.14294815063476562\n",
      "8 0.624 3  frac of faulty traj: 0.0  time= 0.14519309997558594\n",
      "8 0.73 4  frac of faulty traj: 0.0  time= 0.13091707229614258\n",
      "8 0.73 3  frac of faulty traj: 0.0  time= 0.14469408988952637\n",
      "8 0.836 4  frac of faulty traj: 0.01  time= 0.11221003532409668\n",
      "8 0.836 3  frac of faulty traj: 0.01  time= 0.14403581619262695\n",
      "12 0.412 6  frac of faulty traj: 0.0  time= 0.607403039932251\n",
      "12 0.412 5  frac of faulty traj: 0.0  time= 0.618149995803833\n",
      "12 0.518 6  frac of faulty traj: 0.0  time= 0.6111071109771729\n",
      "12 0.518 5  frac of faulty traj: 0.0  time= 0.6133849620819092\n",
      "12 0.624 6  frac of faulty traj: 0.005  time= 0.5928888320922852\n",
      "12 0.624 5  frac of faulty traj: 0.0  time= 0.6292998790740967\n",
      "12 0.73 6  frac of faulty traj: 0.04  time= 0.530825138092041\n",
      "12 0.73 5  frac of faulty traj: 0.01  time= 0.5996139049530029\n",
      "12 0.836 6  frac of faulty traj: 0.06  time= 0.4630260467529297\n",
      "12 0.836 5  frac of faulty traj: 0.0  time= 0.5921857357025146\n",
      "16 0.412 8  frac of faulty traj: 0.0  time= 6.544665098190308\n",
      "16 0.412 7  frac of faulty traj: 0.0  time= 6.4034669399261475\n",
      "16 0.518 8  frac of faulty traj: 0.0  time= 6.515507936477661\n",
      "16 0.518 7  frac of faulty traj: 0.0  time= 6.439548969268799\n",
      "16 0.624 8  frac of faulty traj: 0.025  time= 6.099621057510376\n",
      "16 0.624 7  frac of faulty traj: 0.0  time= 6.43411111831665\n",
      "16 0.73 8  frac of faulty traj: 0.05  time= 5.537294864654541\n",
      "16 0.73 7  frac of faulty traj: 0.0  time= 6.26686692237854\n",
      "16 0.836 8  frac of faulty traj: 0.045  time= 4.944508075714111\n",
      "16 0.836 7  frac of faulty traj: 0.0  time= 6.17546820640564\n"
     ]
    }
   ],
   "source": [
    "if which_machine == 'emulator':\n",
    "    final_direc = 'data/emulator_data/emulator_sep_data/'\n",
    "    outcome_direc = 'data/emulator_data/measurement_data_all_qubits_noisy'\n",
    "L_list = [8,12,16]\n",
    "# p_list = [0.571,0.624,0.677,0.73,0.783]\n",
    "p_list = [0.412,0.518,0.624,0.73,0.836]\n",
    "\n",
    "half_depth=True #when half_depth is true only L//2 layers of outcomes are used for decoding, otherwise L layers are used\n",
    "\n",
    "sep_decoder_2.collect_sep_data(L_list=L_list,p_list=p_list,depth_ratio=1,half_depth=half_depth\n",
    "is_noisy=True, final_direc=final_direc,outcomes_filedir=outcome_direc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename):\n",
    "\n",
    "    with open(filename,'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "\n",
    "    return data\n",
    "\n",
    "def plot_success_prob(data,L_list,charge_fac = 0,N_samples=-1,marker='o'):\n",
    "    ent = {}\n",
    "    err = {}\n",
    "    for L in L_list[:]:\n",
    "        ent[L] = []\n",
    "        err[L] = []\n",
    "        p_list = list(data[L].keys())\n",
    "        for p in p_list:\n",
    "            tempQ = list(data[L][p][L//2])[:N_samples]\n",
    "            tempQ2 = list(data[L][p][L//2-1])[:N_samples]\n",
    "            temp = tempQ + tempQ2\n",
    "            print(\"L=\",L,\"p=\",p,\"data_size:\",len(tempQ),len(tempQ2))\n",
    "           \n",
    "            ent[L].append(np.average(temp))\n",
    "            err[L].append(np.std(temp)/(len(temp)-1)**0.5)\n",
    "\n",
    "        pl.errorbar(np.array(p_list),ent[L],yerr=err[L],ls='-',marker=marker,label='L='+str(L))\n",
    "\n",
    "    pl.xlabel(r'$\\gamma$',fontsize=16)\n",
    "    # pl.ylabel(r'$\\langle p \\rangle_{suc}$',fontsize=16)\n",
    "    pl.ylabel(r'Success prob',fontsize=16)\n",
    "\n",
    "    pl.legend(fontsize=16)\n",
    "    pl.tight_layout()\n",
    "\n",
    "def plot_success_ent(data,L_list,charge_fac = 0,N_samples=-1,marker='o'):\n",
    "    ent = {}\n",
    "    err = {}\n",
    "    for L in L_list[:]:\n",
    "        ent[L] = []\n",
    "        err[L] = []\n",
    "        p_list = list(data[L].keys())\n",
    "        for p in p_list:\n",
    "            tempQ = list(data[L][p][L//2])[:N_samples]\n",
    "            tempQ2 = list(data[L][p][L//2-1])[:N_samples]\n",
    "            temp = tempQ + tempQ2\n",
    "            print(\"L=\",L,\"p=\",p,\"data_size:\",len(tempQ),len(tempQ2))\n",
    "            # ent.append(np.sum(np.array(suc_list)>0.5)/len(suc_list))\n",
    "            ent_list = np.array([(-x*np.log(x) - (1-x)*np.log(1-x)) if 0<x<1 else 0 for x in tempQ2+tempQ])\n",
    "            ent[L].append(np.average(ent_list))\n",
    "            err[L].append(np.std(ent_list)/(len(temp)-1)**0.5)\n",
    "\n",
    "        pl.errorbar(np.array(p_list),ent[L],yerr=err[L],ls='-',marker=marker,label='L='+str(L))\n",
    "\n",
    "    pl.xlabel(r'$\\gamma$',fontsize=16)\n",
    "    # pl.ylabel(r'$\\langle p \\rangle_{suc}$',fontsize=16)\n",
    "    pl.ylabel(r'Success entropy',fontsize=16)\n",
    "\n",
    "    pl.legend(fontsize=16)\n",
    "    pl.tight_layout()\n",
    "\n",
    "def plot_success_binder(data,L_list,N_samples=-1,marker='o',color=None,ls='-',extra_label=''):\n",
    "    binder = {}\n",
    "    err = {}\n",
    "    for L in L_list[:]:\n",
    "        binder[L] = []\n",
    "        err[L] = []\n",
    "        p_list = np.array(list(data[L].keys()))\n",
    "        for p in p_list:\n",
    "            tempQ = list(data[L][p][L//2])[:N_samples]\n",
    "            tempQ2 = list(data[L][p][L//2-1])[:N_samples]\n",
    "            print(\"L=\",L,\"p=\",p,\"data_size:\",len(tempQ),len(tempQ2))\n",
    "            ent_list = np.array([(-x*np.log(x) - (1-x)*np.log(1-x)) if 0<x<1 else 0 for x in tempQ2+tempQ])\n",
    "            mu_1 = np.average(ent_list)\n",
    "            mu_4 = np.average((ent_list-mu_1)**4)\n",
    "            e_4 = np.std(ent_list**4)/len(tempQ+tempQ2)\n",
    "            mu_2 = np.average((ent_list-mu_1)**2)\n",
    "            e_2 = 2*mu_2*np.std(ent_list**2)/len(tempQ+tempQ2)\n",
    "            binder[L].append(1-mu_4/(3*mu_2**2))\n",
    "        \n",
    "        if color is None:\n",
    "            pl.plot(p_list,binder[L],ls=ls,marker=marker,label='L='+str(L)+extra_label)\n",
    "        else:\n",
    "            pl.plot(p_list,binder[L],ls=ls,marker=marker,label='L='+str(L)+extra_label,color=color)\n",
    "\n",
    "    pl.xlabel(r'$\\gamma$',fontsize=16)\n",
    "    pl.ylabel(r'Binder${}_{suc}$',fontsize=16)\n",
    "    pl.legend(fontsize=16)\n",
    "    pl.tight_layout()\n",
    "\n",
    "\n",
    "def plot_success_variance(data,L_list,N_samples=-1,marker='o',color=None,ls='-',extra_label=''):\n",
    "    binder = {}\n",
    "    err = {}\n",
    "    for L in L_list[:]:\n",
    "        binder[L] = []\n",
    "        err[L] = []\n",
    "        p_list = np.array(list(data[L].keys()))\n",
    "        for p in p_list:\n",
    "            tempQ = list(data[L][p][L//2])[:N_samples]\n",
    "            tempQ2 = list(data[L][p][L//2-1])[:N_samples]\n",
    "            print(\"L=\",L,\"p=\",p,\"data_size:\",len(tempQ),len(tempQ2))\n",
    "\n",
    "            ent_list = np.array([(-x*np.log(x) - (1-x)*np.log(1-x)) if 0<x<1 else 0 for x in tempQ2+tempQ])\n",
    "\n",
    "            mu_1 = np.average(ent_list)\n",
    "            \n",
    "            mu_2 = np.average((ent_list-mu_1)**2)\n",
    "            \n",
    "            binder[L].append(mu_2)\n",
    "        \n",
    "        if color is None:\n",
    "            pl.plot(p_list,binder[L],ls=ls,marker=marker,label='L='+str(L)+extra_label)\n",
    "        else:\n",
    "            pl.plot(p_list,binder[L],ls=ls,marker=marker,label='L='+str(L)+extra_label,color=color)\n",
    "\n",
    "    pl.xlabel(r'$\\gamma$',fontsize=16)\n",
    "    pl.ylabel(r'Binder${}_{suc}$',fontsize=16)\n",
    "    pl.legend(fontsize=16)\n",
    "    pl.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_cycle = pl.rcParams['axes.prop_cycle']\n",
    "colors = prop_cycle.by_key()['color']\n",
    "\n",
    "pl.figure(1)\n",
    "\n",
    "\n",
    "data=load_data('data/emulator_data/emulator_sep_data_constant_depth/seed=1_all_qubits_noisy')\n",
    "L_list = [8,12,16][:]\n",
    "plot_success_ent(data,L_list,marker='s',N_samples=-1)\n",
    "# plot_success_binder(data,L_list,marker='s',N_samples=-1,ls='-', extra_label='_noisy_emulator')\n",
    "\n",
    "\n",
    "\n",
    "data=load_data('data/emulator_data/emulator_sep_data/seed=1_all_qubits_noisy')\n",
    "L_list = [8,12,16][:]\n",
    "plot_success_ent(data,L_list,marker='s',N_samples=-1)\n",
    "# plot_success_binder(data,L_list,marker='s',N_samples=-1,ls='-', extra_label='_noisy_emulator')\n",
    "# pl.yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L</th>\n",
       "      <th>shots</th>\n",
       "      <th>p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [L, shots, p]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L</th>\n",
       "      <th>shots</th>\n",
       "      <th>p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0.571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0.624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0.677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0.730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0.783</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     L  shots      p\n",
       "0  8.0  200.0  0.571\n",
       "1  8.0  200.0  0.624\n",
       "2  8.0  200.0  0.677\n",
       "3  8.0  200.0  0.730\n",
       "4  8.0  200.0  0.783"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# file_direc = 'data/hardware_data/handle_data/'\n",
    "# if not os.path.isdir(file_direc):\n",
    "#     os.makedirs(file_direc)\n",
    "\n",
    "\n",
    "# previous_job_number = len(os.listdir(file_direc))\n",
    "# file_direc = file_direc + str(previous_job_number+1) + '/'\n",
    "# if not os.path.isdir(file_direc):\n",
    "#     os.makedirs(file_direc)\n",
    "\n",
    "\n",
    "# df = pd.DataFrame()\n",
    "# df['L'] = []\n",
    "# df['shots'] = []\n",
    "# df['p'] = []\n",
    "# display(df)\n",
    "\n",
    "# number_of_p = len(p_list)\n",
    "# for L in L_list:\n",
    "#     for p in p_list:\n",
    "#         temp = pd.DataFrame({'L':[L],'p':[p],'shots':[n_shots]})\n",
    "#         df = pd.concat([df,temp],ignore_index=True)\n",
    "\n",
    "# display(df)\n",
    "# df.to_csv(file_direc+'information.csv')\n",
    "\n",
    "# with open(file_direc+'handle_dic','wb') as f:\n",
    "#     pickle.dump(handle_dict,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('qtuum': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "db9ce0fd49c82ada94c617a539798de1f12c52da51d869905941d2156c3668d9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
