{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%matplotlib qt5\n",
    "import matplotlib.pyplot as pl\n",
    "import os\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/utkarshagrawal/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.25.0 is required for this version of SciPy (detected version 1.26.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/utkarshagrawal/Documents/Postdoc/U_1_exp/Weak measurements\n",
      "test\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "from sep_decoder_2 import sep_dynamics_2\n",
    "from quantum_decoder import quantum_dynamics_2\n",
    "from biased_decoder import biased_dynamics\n",
    "from circuit_numpy_utils import get_circuit, get_diffusion_constants\n",
    "from circuit_generation_multiple_ancilla import get_circuit_parameters\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_cycle = pl.rcParams['axes.prop_cycle']\n",
    "colors = prop_cycle.by_key()['color'][:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 0, 2, 1, 5, 3]\n",
      "[2, 1, 3, 5, 4, 0]\n"
     ]
    }
   ],
   "source": [
    "indices = list(range(6))\n",
    "rng = np.random.default_rng(1)\n",
    "rng.shuffle(indices)\n",
    "print(indices)\n",
    "rng.shuffle(indices)\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_data(filename='nothing_fixed'):\n",
    "\n",
    "    with open(filename,'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "\n",
    "    return data\n",
    "\n",
    "def get_ancilla_data(data,L_list,temp_quan=1,p_selected=[]):\n",
    "    ent = {}\n",
    "    err = {}\n",
    "    var = {}\n",
    "    var_err = {}\n",
    "    for i,L in enumerate(L_list[:]):\n",
    "        ent[L] = {}\n",
    "        err[L] = {}\n",
    "        var[L] = {} \n",
    "        var_err[L] = {}\n",
    "        p_list = list(sorted(data[L].keys()))\n",
    "        # p_list = [0.412,0.518,0.624,0.73,0.836]\n",
    "        p_data = []\n",
    "        for p in p_list:\n",
    "            if len(p_selected)>0:\n",
    "                if p not in p_selected:\n",
    "                    continue\n",
    "            p_data.append(p)\n",
    "            if temp_quan == 0:\n",
    "                # print(p,L)\n",
    "                # print(data[L][p])\n",
    "                N = len(data[L][p][L//2])\n",
    "                if L!=14: N=N\n",
    "                tempQ = list(data[L][p][L//2])[:N]\n",
    "                N = len(data[L][p][L//2-1])\n",
    "                if L!=14: N=N\n",
    "                tempQ2 = list(data[L][p][L//2-1])[:N]\n",
    "            else:\n",
    "                N = len(data[L][p][L//2])\n",
    "                if L!=14: N=N\n",
    "                tempQ = [data[L][p][L//2][i][-1] for i in range(N)]\n",
    "                N = len(data[L][p][L//2-1])\n",
    "                if L!=14: N=N\n",
    "                tempQ2 = [data[L][p][L//2-1][i][-1] for i in range(N)]\n",
    "            \n",
    "\n",
    "            temp = np.array(tempQ + tempQ2)\n",
    "            N = len(temp)\n",
    "            print(\"L=\",L,\"p=\",p,\"data_size:\",len(tempQ),len(tempQ2))\n",
    "\n",
    "            entropy = np.array([(-x*np.log(x) - (1-x)*np.log(1-x)) if 0<x<1 else 0 for x in temp])\n",
    "            ydata = entropy\n",
    "            avg = np.average(np.array(ydata))\n",
    "            mu_2 = np.average((np.array(ydata)-avg)**2)\n",
    "            mu_4 = np.average((np.array(ydata)-avg)**4)\n",
    "            ent[L][p] = avg\n",
    "            err[L][p] = (np.std(np.array(ydata))/(N-1)**0.5)\n",
    "            var[L][p] = mu_2\n",
    "            var_err[L][p] = np.sqrt((mu_4-(N-3)*mu_2**2/(N-1))/N)\n",
    "\n",
    "    return ent,err,var,var_err\n",
    "\n",
    "\n",
    "def get_suc_prob_data(data,L_list,temp_quan=1,p_selected=[]):\n",
    "    ent = {}\n",
    "    err = {}\n",
    "    var = {}\n",
    "    var_err = {}\n",
    "    for i,L in enumerate(L_list[:]):\n",
    "        ent[L] = {}\n",
    "        err[L] = {}\n",
    "        var[L] = {} \n",
    "        var_err[L] = {}\n",
    "        p_list = list(sorted(data[L].keys()))\n",
    "        # p_list = [0.412,0.518,0.624,0.73,0.836]\n",
    "        p_data = []\n",
    "        for p in p_list:\n",
    "            if len(p_selected)>0:\n",
    "                if p not in p_selected:\n",
    "                    continue\n",
    "            p_data.append(p)\n",
    "            if temp_quan == 0:\n",
    "                # print(p,L)\n",
    "                # print(data[L][p])\n",
    "                N = len(data[L][p][L//2])\n",
    "                if L!=14: N=N\n",
    "                tempQ = list(data[L][p][L//2])[:N]\n",
    "                N = len(data[L][p][L//2-1])\n",
    "                if L!=14: N=N\n",
    "                tempQ2 = list(data[L][p][L//2-1])[:N]\n",
    "            else:\n",
    "                N = len(data[L][p][L//2])\n",
    "                if L!=14: N=N\n",
    "                tempQ = [data[L][p][L//2][i][-1] for i in range(N)]\n",
    "                N = len(data[L][p][L//2-1])\n",
    "                if L!=14: N=N\n",
    "                tempQ2 = [data[L][p][L//2-1][i][-1] for i in range(N)]\n",
    "            \n",
    "\n",
    "            temp = np.array(tempQ + tempQ2)\n",
    "            N = len(temp)\n",
    "            print(\"L=\",L,\"p=\",p,\"data_size:\",len(tempQ),len(tempQ2))\n",
    "\n",
    "            entropy = np.array([(-x*np.log(x) - (1-x)*np.log(1-x)) if 0<x<1 else 0 for x in temp])\n",
    "            ydata = temp\n",
    "            avg = np.average(np.array(ydata))\n",
    "            mu_2 = np.average((np.array(ydata)-avg)**2)\n",
    "            mu_4 = np.average((np.array(ydata)-avg)**4)\n",
    "            ent[L][p] = avg\n",
    "            err[L][p] = (np.std(np.array(ydata))/(N-1)**0.5)\n",
    "            var[L][p] = mu_2\n",
    "            var_err[L][p] = np.sqrt((mu_4-(N-3)*mu_2**2/(N-1))/N)\n",
    "\n",
    "    return ent,err,var,var_err\n",
    "\n",
    "def get_binder_data(data,L_list,temp_quan=1,p_selected=[]):\n",
    "    binder = {}\n",
    "    for i,L in enumerate(L_list[:]):\n",
    "        binder[L] = {}\n",
    "        p_list = list(sorted(data[L].keys()))\n",
    "        # p_list = [0.412,0.518,0.624,0.73,0.836]\n",
    "        p_data = []\n",
    "        for p in p_list:\n",
    "            if len(p_selected)>0:\n",
    "                if p not in p_selected:\n",
    "                    continue\n",
    "            p_data.append(p)\n",
    "            if temp_quan == 0:\n",
    "                # print(p,L)\n",
    "                # print(data[L][p])\n",
    "                N = len(data[L][p][L//2])\n",
    "                if L!=14: N=N\n",
    "                tempQ = list(data[L][p][L//2])[:N]\n",
    "                N = len(data[L][p][L//2-1])\n",
    "                if L!=14: N=N\n",
    "                tempQ2 = list(data[L][p][L//2-1])[:N]\n",
    "            else:\n",
    "                N = len(data[L][p][L//2])\n",
    "                if L!=14: N=N\n",
    "                tempQ = [data[L][p][L//2][i][-1] for i in range(N)]\n",
    "                N = len(data[L][p][L//2-1])\n",
    "                if L!=14: N=N\n",
    "                tempQ2 = [data[L][p][L//2-1][i][-1] for i in range(N)]\n",
    "            \n",
    "\n",
    "            temp = np.array(tempQ + tempQ2)\n",
    "            N = len(temp)\n",
    "            print(\"L=\",L,\"p=\",p,\"data_size:\",len(tempQ),len(tempQ2))\n",
    "            entropy = np.array([(-x*np.log(x) - (1-x)*np.log(1-x)) if 0<x<1 else 0 for x in temp])\n",
    "\n",
    "            ydata = entropy\n",
    "            avg = np.average(np.array(ydata))\n",
    "            mu_2 = np.average((np.array(ydata)-avg)**2)\n",
    "            mu_4 = np.average((np.array(ydata)-avg)**4)\n",
    "            binder[L][p] = (1-mu_4/(3*mu_2**2))\n",
    "\n",
    "\n",
    "    return binder\n",
    "\n",
    "\n",
    "\n",
    "def get_acc_data(data,L_list,temp_quan=1,p_selected=[]):\n",
    "    ent = {}\n",
    "    err = {}\n",
    "    var = {}\n",
    "    var_err = {}\n",
    "    for i,L in enumerate(L_list[:]):\n",
    "        ent[L] = {}\n",
    "        err[L] = {}\n",
    "        var[L] = {} \n",
    "        var_err[L] = {}\n",
    "        p_list = list(sorted(data[L].keys()))\n",
    "        # p_list = [0.412,0.518,0.624,0.73,0.836]\n",
    "        p_data = []\n",
    "        for p in p_list:\n",
    "            if len(p_selected)>0:\n",
    "                if p not in p_selected:\n",
    "                    continue\n",
    "            p_data.append(p)\n",
    "            if temp_quan == 0:\n",
    "                # print(p,L)\n",
    "                # print(data[L][p])\n",
    "                N = len(data[L][p][L//2])\n",
    "                if L!=14: N=N\n",
    "                tempQ = list(data[L][p][L//2])[:N]\n",
    "                N = len(data[L][p][L//2-1])\n",
    "                if L!=14: N=N\n",
    "                tempQ2 = list(data[L][p][L//2-1])[:N]\n",
    "            else:\n",
    "                N = len(data[L][p][L//2])\n",
    "                if L!=14: N=N\n",
    "                tempQ = [data[L][p][L//2][i][-1] for i in range(N)]\n",
    "                N = len(data[L][p][L//2-1])\n",
    "                if L!=14: N=N\n",
    "                tempQ2 = [data[L][p][L//2-1][i][-1] for i in range(N)]\n",
    "            \n",
    "\n",
    "            temp = np.array(tempQ + tempQ2)\n",
    "            N = len(temp)\n",
    "            print(\"L=\",L,\"p=\",p,\"data_size:\",len(tempQ),len(tempQ2))\n",
    "\n",
    "            entropy = np.array([(-x*np.log(x) - (1-x)*np.log(1-x)) if 0<x<1 else 0 for x in temp])\n",
    "            ydata = temp>0.5\n",
    "            avg = np.average(np.array(ydata))\n",
    "            mu_2 = np.average((np.array(ydata)-avg)**2)\n",
    "            mu_4 = np.average((np.array(ydata)-avg)**4)\n",
    "            ent[L][p] = avg\n",
    "            err[L][p] = (np.std(np.array(ydata))/(N-1)**0.5)\n",
    "            var[L][p] = mu_2\n",
    "            var_err[L][p] = np.sqrt((mu_4-(N-3)*mu_2**2/(N-1))/N)\n",
    "\n",
    "    return ent,err,var,var_err\n",
    "\n",
    "\n",
    "## obselete function below\n",
    "def plot_success_prob(data,L_list,charge_fac = 0,N_samples=-1,marker='o',ls='-',post_label = '',color_list = [],ms=6,temp_quan=1,p_selected=[],alpha=1,do_label=True):\n",
    "    ent,err,_,_ = get_suc_prob_data(data,L_list,temp_quan=temp_quan,p_selected=p_selected)\n",
    "    for i,L in enumerate(L_list):\n",
    "        p_data = sorted(list(ent[L].keys()))\n",
    "        ydata = [ent[L][p] for p in p_data]\n",
    "        errdata = [err[L][p] for p in p_data]\n",
    "        if not do_label:\n",
    "            label = ''\n",
    "        else:\n",
    "            label='L='+str(L)+post_label\n",
    "\n",
    "        if not color_list:\n",
    "            pl.errorbar(np.array(p_data)/(np.pi/2),ydata,yerr=errdata,ms=ms,ls=ls,marker=marker,label=label,alpha=alpha)\n",
    "        else:\n",
    "            pl.errorbar(np.array(p_data)/(np.pi/2),ydata,yerr=errdata,ms=ms,color=color_list[i],ls=ls,marker=marker,label=label,alpha=alpha)\n",
    "\n",
    "    pl.xlabel(r'$\\gamma$',fontsize=16)\n",
    "    # pl.ylabel(r'$\\langle p \\rangle_{suc}$',fontsize=16)\n",
    "    pl.ylabel(r'$P_{\\rm corr}$',fontsize=16)\n",
    "    # pl.ylabel(r'Accuracy',fontsize=16)\n",
    "    pl.legend(fontsize=11)\n",
    "    pl.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#obselete functions below\n",
    "def plot_success_binder(data,L_list,charge_fac = 0,N_samples=-1,marker='o',ls='-',post_label = '',do_label=True,color_list = [],ms=6,temp_quan=1,p_selected=[],alpha=1):\n",
    "    binder = {}\n",
    "    err = {}\n",
    "    for i,L in enumerate(L_list[:]):\n",
    "        binder[L] = []\n",
    "        err[L] = []\n",
    "        p_list = list(sorted(data[L].keys()))\n",
    "        # p_list = [0.412,0.518,0.624,0.73,0.836]\n",
    "        p_data = []\n",
    "        for p in p_list:\n",
    "            if len(p_selected)>0:\n",
    "                if p not in p_selected:\n",
    "                    continue\n",
    "            p_data.append(p)\n",
    "            if temp_quan == 0:\n",
    "                # print(p,L)\n",
    "                # print(data[L][p])\n",
    "                N = len(data[L][p][L//2])\n",
    "                if L!=14: N=N\n",
    "                tempQ = list(data[L][p][L//2])[:N]\n",
    "                N = len(data[L][p][L//2-1])\n",
    "                if L!=14: N=N\n",
    "                tempQ2 = list(data[L][p][L//2-1])[:N]\n",
    "            else:\n",
    "                N = len(data[L][p][L//2])\n",
    "                if L!=14: N=N\n",
    "                tempQ = [data[L][p][L//2][i][-1] for i in range(N)]\n",
    "                N = len(data[L][p][L//2-1])\n",
    "                if L!=14: N=N\n",
    "                tempQ2 = [data[L][p][L//2-1][i][-1] for i in range(N)]\n",
    "            \n",
    "\n",
    "            temp = tempQ + tempQ2\n",
    "            print(\"L=\",L,\"p=\",p,\"data_size:\",len(tempQ),len(tempQ2))\n",
    "            # ent[L].append(np.sum(np.array(tempQ+tempQ2)>0.5)/len(tempQ+tempQ2))\n",
    "            # err[L].append(0)\n",
    "            ent_list = np.array([(-x*np.log(x) - (1-x)*np.log(1-x)) if 0<x<1 else 0 for x in tempQ2+tempQ])\n",
    "\n",
    "            ent_list = np.array(temp)\n",
    "            \n",
    "            mu_1 = np.average(ent_list)\n",
    "            mu_4 = np.average((ent_list-mu_1)**4)\n",
    "            e_4 = np.std(ent_list**4)/len(tempQ+tempQ2)\n",
    "            mu_2 = np.average((ent_list-mu_1)**2)\n",
    "            e_2 = 2*mu_2*np.std(ent_list**2)/len(tempQ+tempQ2)\n",
    "            # binder[L].append(1-mu_4/(3*mu_2**2))\n",
    "            # err[L].append((e_4/mu_2 + mu_4*e_2/(mu_2**2))*0)\n",
    "\n",
    "            N = len(temp)\n",
    "            binder[L].append(mu_2)\n",
    "            err[L].append(np.sqrt((mu_4-(N-3)*mu_2**2/(N-1))/N))\n",
    "        if not do_label:\n",
    "            label = ''\n",
    "        else:\n",
    "            label='L='+str(L)+post_label\n",
    "        if not color_list:\n",
    "            pl.errorbar(np.array(p_data)/(np.pi/2),binder[L],yerr=err[L],ms=ms,ls=ls,marker=marker,label=label,alpha=alpha)\n",
    "        else:\n",
    "            pl.errorbar(np.array(p_data)/(np.pi/2),binder[L],yerr=err[L],ms=ms,color=color_list[i],ls=ls,marker=marker,label=label,alpha=alpha)\n",
    "    pl.xlabel(r'$\\gamma$',fontsize=16)\n",
    "    pl.ylabel(r'Variance${}_{suc}$',fontsize=16)\n",
    "    pl.legend(fontsize=10)\n",
    "    pl.tight_layout()\n",
    "\n",
    "def plot_acc_binder(data,L_list,N_samples=-1,marker='-o'):\n",
    "    binder = {}\n",
    "    err = {}\n",
    "    for L in L_list[:]:\n",
    "        binder[L] = []\n",
    "        err[L] = []\n",
    "        p_list = np.array(list(data[L].keys()))\n",
    "        for p in p_list:\n",
    "            tempQ = list(data[L][p][L//2])[:N_samples]\n",
    "            tempQ2 = list(data[L][p][L//2-1])[:N_samples]\n",
    "            print(\"L=\",L,\"p=\",p,\"data_size:\",len(tempQ),len(tempQ2))\n",
    "            # ent[L].append(np.sum(np.array(tempQ+tempQ2)>0.5)/len(tempQ+tempQ2))\n",
    "            # err[L].append(0)\n",
    "            ent_list = np.array([x for x in tempQ2+tempQ])\n",
    "            mu_1 = np.average(ent_list)\n",
    "            mu_4 = np.average((ent_list-mu_1)**4)\n",
    "            e_4 = np.std(ent_list**4)/len(tempQ+tempQ2)\n",
    "            mu_2 = np.average((ent_list-mu_1)**2)\n",
    "            e_2 = 2*mu_2*np.std(ent_list**2)/len(tempQ+tempQ2)\n",
    "            binder[L].append(1-mu_4/(3*mu_2**2))\n",
    "            err[L].append((e_4/mu_2 + mu_4*e_2/(mu_2**2)))\n",
    "\n",
    "        pl.errorbar(p_list,binder[L],yerr=err[L],ls='-',marker=marker,label='L='+str(L))\n",
    "\n",
    "    pl.xlabel(r'$\\gamma$',fontsize=16)\n",
    "    pl.ylabel(r'Binder${}_{acc}$',fontsize=16)\n",
    "    pl.legend(fontsize=16)\n",
    "    pl.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/utkarshagrawal/anaconda3/lib/python3.9/site-packages/numpy/linalg/linalg.py:2180: RuntimeWarning: divide by zero encountered in det\n",
      "  r = _umath_linalg.det(a, signature=signature)\n",
      "/Users/utkarshagrawal/anaconda3/lib/python3.9/site-packages/numpy/linalg/linalg.py:2180: RuntimeWarning: invalid value encountered in det\n",
      "  r = _umath_linalg.det(a, signature=signature)\n"
     ]
    }
   ],
   "source": [
    "L=10\n",
    "Q=5\n",
    "p=0.651\n",
    "depth=L\n",
    "seed=1\n",
    "U_list = get_circuit(L,depth,'Special',seed,5)\n",
    "D_list = get_diffusion_constants(circuit_layer=U_list)\n",
    "\n",
    "filedir = 'data/qiskit_data/measurement_data_all_qubits_special'\n",
    "filename = filedir +'/L='+str(L)+'_depth='+str(depth)+'_Q='+str(Q)+'_p=' + str(p)+ '_seed='+str(seed)+'.imdat'\n",
    "with open(filename,'rb') as f:\n",
    "    data_raw,_,_ = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_list = []\n",
    "for data in data_raw[10:11]:\n",
    "    result = sep_dynamics_2(data[0],Q,p,t_scr=5,neel_state=True)\n",
    "    result_list.extend([result]*data[1])\n",
    "# file = 'data/biased_sep_data/seed=1_all_qubits_special_scrambled'\n",
    "# data=load_data(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2, 2, 2, 2, 2, 2, 2, 2, 2)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(result_list[0][1]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_RNN_hardware_data_suc_prob(L,gamma_arr_exp):\n",
    "    if L==6 :num_RNN_units = 32\n",
    "    else: num_RNN_units = 128\n",
    "    dropout = 0.1\n",
    "    RNN_dropout = 0.1\n",
    "    learning_rate = 1E-3\n",
    "    batch_size = 32\n",
    "    num_epochs = 100\n",
    "    if L==6:\n",
    "        num_shots = 10000\n",
    "    elif L==10:\n",
    "        num_shots = 160000\n",
    "    elif L==14:\n",
    "        num_shots = 640000\n",
    "    accuracy_arr = []\n",
    "    accuracy_arr_err = []\n",
    "    gamma_arr_new = []\n",
    "    itera=4\n",
    "    for i in range(len(gamma_arr_exp)):\n",
    "        try:\n",
    "            arr = np.load(\"RNN_data/data_hardware/succ_proba_array_weak_hardware_post_LSTM_decoder_{}_learning_rate_{}_num_epochs_{}_dropout_{}_RNN_dropout_{}_batch_size_{}_L_{}_p_{}_num_shots_{}_iter_{}.npy\".format(num_RNN_units,learning_rate,num_epochs,dropout,RNN_dropout,batch_size,L,gamma_arr_exp[i],num_shots,itera))\n",
    "            #accuracy_arr.append(arr[len(arr)-1])\n",
    "            \n",
    "            accuracy_arr.append(np.mean(arr))\n",
    "            accuracy_arr_err.append(np.std(arr)/np.sqrt(2*num_shots))\n",
    "            gamma_arr_new.append(gamma_arr_exp[i])\n",
    "        except:\n",
    "            print(\"ignored\", gamma_arr_exp[i],L)\n",
    "    return gamma_arr_new,accuracy_arr, accuracy_arr_err\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_RNN_simulation_data_suc_prob(L,gamma_arr_exp):\n",
    "    if L==6 :num_RNN_units = 128\n",
    "    else: num_RNN_units = 128\n",
    "    dropout = 0.1\n",
    "    RNN_dropout = 0.1\n",
    "    learning_rate = 0.001\n",
    "    batch_size = 32\n",
    "    num_epochs = 100\n",
    "    itera=1\n",
    "    if L==6:\n",
    "        num_shots = 10000\n",
    "    elif L==10:\n",
    "        num_shots = 160000\n",
    "    elif L==14:\n",
    "        num_shots = 640000\n",
    "    accuracy_arr = []\n",
    "    accuracy_arr_err = []\n",
    "    gamma_arr_new = []\n",
    "    for i in range(len(gamma_arr_exp)):\n",
    "        try:\n",
    "            arr = np.load(\"RNN_data/data_weak/succ_proba_array_weak_LSTM_decoder_{}_learning_rate_{}_num_epochs_{}_dropout_{}_RNN_dropout_{}_batch_size_{}_L_{}_p_{}_num_shots_{}_iter_{}.npy\".format(num_RNN_units,learning_rate,num_epochs,dropout,RNN_dropout,batch_size,L,gamma_arr_exp[i],num_shots,itera))\n",
    "            #accuracy_arr.append(arr[len(arr)-1])\n",
    "            accuracy_arr.append(np.mean(arr))\n",
    "            # accuracy_arr_err.append(np.std(arr)/np.sqrt(2*num_shots))\n",
    "            accuracy_arr_err.append(np.std(arr))\n",
    "            gamma_arr_new.append(gamma_arr_exp[i])\n",
    "        except:\n",
    "            print(\"ignored\", gamma_arr_exp[i],L)\n",
    "    return gamma_arr_new,accuracy_arr,accuracy_arr_err\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_RNN_hardware_data_acc(L,gamma_arr_exp):\n",
    "    if L==6 :num_RNN_units = 32\n",
    "    else: num_RNN_units = 128\n",
    "    dropout = 0.1\n",
    "    RNN_dropout = 0.1\n",
    "    learning_rate = 1E-3\n",
    "    batch_size = 32\n",
    "    num_epochs = 100\n",
    "    if L==6:\n",
    "        num_shots = 10000\n",
    "    elif L==10:\n",
    "        num_shots = 160000\n",
    "    elif L==14:\n",
    "        num_shots = 640000\n",
    "    accuracy_arr = []\n",
    "    accuracy_arr_err = []\n",
    "    gamma_arr_new = []\n",
    "    itera=4\n",
    "    for i in range(len(gamma_arr_exp)):\n",
    "        try:\n",
    "            arr = np.load(\"RNN_data/data_hardware/accuracy_array_weak_hardware_post_LSTM_decoder_{}_learning_rate_{}_num_epochs_{}_dropout_{}_RNN_dropout_{}_batch_size_{}_L_{}_p_{}_num_shots_{}_iter_{}.npy\".format(num_RNN_units,learning_rate,num_epochs,dropout,RNN_dropout,batch_size,L,gamma_arr_exp[i],num_shots,itera))\n",
    "            #accuracy_arr.append(arr[len(arr)-1])\n",
    "            \n",
    "            accuracy_arr.append(np.mean(arr))\n",
    "            accuracy_arr_err.append(np.std(arr)/np.sqrt(2*num_shots))\n",
    "            gamma_arr_new.append(gamma_arr_exp[i])\n",
    "        except:\n",
    "            print(\"ignored\", gamma_arr_exp[i],L)\n",
    "    return gamma_arr_new,accuracy_arr, accuracy_arr_err\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_RNN_simulation_data_acc(L,gamma_arr_exp):\n",
    "    if L==6 :num_RNN_units = 128\n",
    "    else: num_RNN_units = 128\n",
    "    dropout = 0.1\n",
    "    RNN_dropout = 0.1\n",
    "    learning_rate = 0.001\n",
    "    batch_size = 32\n",
    "    num_epochs = 100\n",
    "    itera=1\n",
    "    if L==6:\n",
    "        num_shots = 10000\n",
    "    elif L==10:\n",
    "        num_shots = 160000\n",
    "    elif L==14:\n",
    "        num_shots = 640000\n",
    "    accuracy_arr = []\n",
    "    accuracy_arr_err = []\n",
    "    gamma_arr_new = []\n",
    "    for i in range(len(gamma_arr_exp)):\n",
    "        try:\n",
    "            arr = np.load(\"RNN_data/data_weak/accuracy_array_weak_LSTM_decoder_{}_learning_rate_{}_num_epochs_{}_dropout_{}_RNN_dropout_{}_batch_size_{}_L_{}_p_{}_num_shots_{}_iter_{}.npy\".format(num_RNN_units,learning_rate,num_epochs,dropout,RNN_dropout,batch_size,L,gamma_arr_exp[i],num_shots,itera))\n",
    "            #accuracy_arr.append(arr[len(arr)-1])\n",
    "            accuracy_arr.append(np.mean(arr))\n",
    "            accuracy_arr_err.append(np.std(arr)/np.sqrt(2*num_shots))\n",
    "            gamma_arr_new.append(gamma_arr_exp[i])\n",
    "        except:\n",
    "            print(\"ignored\", gamma_arr_exp[i],L)\n",
    "    return gamma_arr_new,accuracy_arr,accuracy_arr_err\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_p(name:str):\n",
    "    p = 0\n",
    "    index1 = name.index('p=')\n",
    "    index2 = name.index('_seed=')\n",
    "    p = float(name[index1+2:index2])\n",
    "    return p\n",
    "\n",
    "def get_Q(name:str):\n",
    "    g = 0\n",
    "    index1 = name.index('Q=')\n",
    "    index2 = name.index('_p=')\n",
    "\n",
    "    g = float(name[index1+2:index2])\n",
    "    return g\n",
    "\n",
    "def get_T(name:str):\n",
    "    T = 0\n",
    "    index2 = name.index('_Q')\n",
    "    index1 = name.index('depth=')\n",
    "    T = int(name[index1+6:index2])\n",
    "    return T\n",
    "\n",
    "def get_L(name:str):\n",
    "    N = 0\n",
    "    index1 = name.index('L=')\n",
    "    index2 = name.index('_depth=')\n",
    "    N = int(name[index1+2:index2])\n",
    "    return N\n",
    "\n",
    "def total_samples():\n",
    "\n",
    "    sample_dict = {}\n",
    "\n",
    "    root_direc = '../Quantinum/Weak measurements/data/hardware_data/measurement_data_all_qubits_noisy_depth_ratio=0.5'\n",
    "    for file in os.listdir(root_direc):\n",
    "        L,Q,p = get_L(file),get_Q(file),get_p(file)\n",
    "        with open(root_direc+'/'+file,'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "        count = 0\n",
    "        for x in data:\n",
    "            count += x[1]\n",
    "        sample_dict[(L,Q,p)] = count\n",
    "    \n",
    "    return sample_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling cose plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0.079: [0.11499999999999999, 0.345, 0], 0.236: [0.09250000000000003, 0.365, 0.57125], 0.516: [0.07499999999999996, 0.38249999999999995, 0.6174999999999999], 0.785: [0.08499999999999996, 0.345, 0.6591666666666667], 0.92: [0.18500000000000005, 0.41000000000000003, 0.654], 1.122: [0.14500000000000002, 0.38749999999999996, 0.665]}\n"
     ]
    }
   ],
   "source": [
    "# Sampling cost plot\n",
    "L_list = [6,10,14]\n",
    "pl.figure(1,figsize=(6,5))\n",
    "\n",
    "samples = total_samples()\n",
    "hardware_data_file =  '../Quantinum/Weak measurements/data/hardware_data/biased_sep_data_neel_depth_ratio=0.5/seed=1_all_qubits_special_scrambled_decoding_protocol=3_noisy'\n",
    "with open(hardware_data_file,'rb') as f:\n",
    "    hardware_data = pickle.load(f)\n",
    "\n",
    "cost_data = {}\n",
    "p_list = [0.079,0.236,0.516,0.785,0.92,1.122]\n",
    "for p in p_list:\n",
    "    cost_data[p] = []\n",
    "    for L in L_list:\n",
    "        samples_ran = 0\n",
    "        samples_used = 0\n",
    "        for Q in [L//2-1,L//2]:\n",
    "            if (L,Q,p) not in samples:\n",
    "                continue\n",
    "            samples_ran += samples[(L,Q,p)]\n",
    "            samples_used += len(hardware_data[L][p][Q])\n",
    "        if samples_ran!=0: cost_data[p].append(1-samples_used/samples_ran)\n",
    "        else: cost_data[p].append(0)\n",
    "\n",
    "[pl.plot(L_list,cost_data[p],'-o',label=r'$\\gamma={}$'.format(round(p*2/np.pi,4))) for p in [0.236,0.785,1.122]]\n",
    "print(cost_data)\n",
    "pl.legend(fontsize=16)\n",
    "pl.ylabel(r'Sampling cost',fontsize=22)\n",
    "pl.xlabel(r'L',fontsize=22)\n",
    "pl.xticks([6,10,14],fontsize=22)\n",
    "pl.yticks(pl.yticks()[0][::2],fontsize=22)\n",
    "pl.tight_layout()\n",
    "# pl.plot(p_list,[cost_data[p][2] for p in p_list],'-o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(10, 5.0, 0.236): 200,\n",
       " (14, 6.0, 0.785): 600,\n",
       " (6, 3.0, 0.079): 200,\n",
       " (14, 6.0, 1.122): 200,\n",
       " (10, 5.0, 1.122): 200,\n",
       " (10, 4.0, 0.92): 700,\n",
       " (6, 3.0, 0.516): 200,\n",
       " (10, 5.0, 0.92): 700,\n",
       " (14, 6.0, 0.92): 800,\n",
       " (14, 6.0, 0.236): 400,\n",
       " (10, 5.0, 0.785): 300,\n",
       " (14, 7.0, 0.92): 700,\n",
       " (14, 7.0, 1.122): 200,\n",
       " (14, 7.0, 0.785): 600,\n",
       " (6, 2.0, 0.92): 100,\n",
       " (10, 4.0, 0.236): 200,\n",
       " (6, 2.0, 0.079): 200,\n",
       " (6, 3.0, 0.92): 100,\n",
       " (10, 4.0, 0.785): 300,\n",
       " (14, 7.0, 0.236): 400,\n",
       " (6, 2.0, 0.516): 200,\n",
       " (10, 4.0, 1.122): 200,\n",
       " (6, 2.0, 0.785): 200,\n",
       " (10, 4.0, 0.516): 200,\n",
       " (6, 2.0, 1.122): 200,\n",
       " (14, 7.0, 0.516): 400,\n",
       " (10, 4.0, 0.079): 100,\n",
       " (6, 2.0, 0.236): 200,\n",
       " (6, 3.0, 1.122): 200,\n",
       " (10, 5.0, 0.516): 200,\n",
       " (6, 3.0, 0.785): 200,\n",
       " (10, 5.0, 0.079): 100,\n",
       " (6, 3.0, 0.236): 200,\n",
       " (14, 6.0, 0.516): 400}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# no. of samples\n",
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.05029296, 0.15024227, 0.3284958 , 0.49974652, 0.58569019,\n",
       "       0.71428738])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# values of gamma\n",
    "np.array(p_list)*2/np.pi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing mitigation with no mitigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L= 6 p= 0.079 data_size: 200 200\n",
      "L= 6 p= 0.236 data_size: 200 200\n",
      "L= 6 p= 0.516 data_size: 200 200\n",
      "L= 6 p= 0.785 data_size: 200 200\n",
      "L= 6 p= 0.92 data_size: 97 100\n",
      "L= 6 p= 1.122 data_size: 196 197\n",
      "L= 10 p= 0.079 data_size: 100 100\n",
      "L= 10 p= 0.236 data_size: 200 200\n",
      "L= 10 p= 0.516 data_size: 199 200\n",
      "L= 10 p= 0.785 data_size: 285 298\n",
      "L= 10 p= 0.92 data_size: 664 690\n",
      "L= 10 p= 1.122 data_size: 190 200\n",
      "L= 14 p= 0.236 data_size: 400 400\n",
      "L= 14 p= 0.516 data_size: 399 400\n",
      "L= 14 p= 0.785 data_size: 566 580\n",
      "L= 14 p= 0.92 data_size: 636 764\n",
      "L= 14 p= 1.122 data_size: 180 189\n",
      "L= 6 p= 0.079 data_size: 181 173\n",
      "L= 6 p= 0.236 data_size: 183 180\n",
      "L= 6 p= 0.516 data_size: 188 182\n",
      "L= 6 p= 0.785 data_size: 187 179\n",
      "L= 6 p= 0.92 data_size: 84 79\n",
      "L= 6 p= 1.122 data_size: 174 168\n",
      "L= 10 p= 0.079 data_size: 64 67\n",
      "L= 10 p= 0.236 data_size: 136 118\n",
      "L= 10 p= 0.516 data_size: 128 119\n",
      "L= 10 p= 0.785 data_size: 206 187\n",
      "L= 10 p= 0.92 data_size: 442 384\n",
      "L= 10 p= 1.122 data_size: 125 120\n",
      "L= 14 p= 0.236 data_size: 164 179\n",
      "L= 14 p= 0.516 data_size: 158 148\n",
      "L= 14 p= 0.785 data_size: 232 177\n",
      "L= 14 p= 0.92 data_size: 266 253\n",
      "L= 14 p= 1.122 data_size: 73 61\n"
     ]
    }
   ],
   "source": [
    "# Plot comparing mitigation\n",
    "L_list = [6,8,10,12,14,16][:5]\n",
    "L_list = [6,10,14]\n",
    "fig,ax = pl.subplots(1,1)\n",
    "\n",
    "colors = pl.cm.Blues(np.linspace(0.5,1,len(L_list)))\n",
    "\n",
    "depth_ratio=0.5\n",
    "if depth_ratio != 1:\n",
    "    depth_label = '_depth_ratio='+str(depth_ratio) + '/'\n",
    "else:\n",
    "    depth_label = '/'\n",
    "\n",
    "ROOT_DIREC_Q = '../Quantinum/Weak measurements/data/hardware_data/'\n",
    "p_select_Q = [0.079,0.236,0.516,0.785,0.92,1.122] # p values for hardware data\n",
    "file2_Q = ROOT_DIREC_Q+'biased_sep_data'+depth_label+'seed=1_all_qubits_special_scrambled'\n",
    "is_noisy = '_noisy'\n",
    "\n",
    "\n",
    "data2_Q_no_mit = load_data(file2_Q+'_decoding_protocol=0'+is_noisy)\n",
    "suc_no,err_no,_,_ = get_suc_prob_data(data2_Q_no_mit,L_list,temp_quan=0,p_selected=p_select_Q)\n",
    "\n",
    "data2_Q = load_data(file2_Q+'_decoding_protocol=3'+is_noisy)\n",
    "suc,err,_,_ = get_suc_prob_data(data2_Q,L_list,temp_quan=0,p_selected=p_select_Q)\n",
    "\n",
    "lw=2.5\n",
    "for i,L in enumerate(L_list):\n",
    "    xdata = np.array(sorted(list(suc[L].keys())))\n",
    "    ydata = [suc[L][p] for p in xdata]\n",
    "    yerr = [err[L][p] for p in xdata]\n",
    "\n",
    "    ax.errorbar(xdata*2/np.pi,ydata,yerr=yerr,ls='-',color=colors[i],marker='o',lw=2)\n",
    "\n",
    "    xdata = np.array(sorted(list(suc_no[L].keys())))\n",
    "    ydata = [suc_no[L][p] for p in xdata]\n",
    "    yerr = [err_no[L][p] for p in xdata]\n",
    "\n",
    "    ax.errorbar(xdata*2/np.pi,ydata,yerr=yerr,ls='--',color=colors[i],marker='o',lw=2)\n",
    "\n",
    "ax.plot([],[],'-',color='k',label='With error mitigation')\n",
    "ax.plot([],[],':',color='k',label='Without error mitigation')\n",
    "\n",
    "\n",
    "[ax.plot([],[],'-',label=r'$L=$'+str(L)) for L in L_list]\n",
    "\n",
    "ax.tick_params(axis='both', which='major', labelsize=14)\n",
    "ax.tick_params(axis='both', which='major', labelsize=14)\n",
    "\n",
    "label_size = 16\n",
    "\n",
    "ax.set_ylabel(r'Credence $C$',fontsize=label_size)\n",
    "\n",
    "\n",
    "ax.set_xlabel(r'$\\gamma$',fontsize=label_size)\n",
    "\n",
    "ax.legend(fontsize=12)\n",
    "\n",
    "fig.set_tight_layout(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comaparing decoders for accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L= 6 p= 0.07853981633974483 data_size: 10000 10000\n",
      "L= 6 p= 0.15707963267948966 data_size: 10000 10000\n",
      "L= 6 p= 0.23561944901923448 data_size: 10000 10000\n",
      "L= 6 p= 0.314 data_size: 10000 10000\n",
      "L= 6 p= 0.381 data_size: 10000 10000\n",
      "L= 6 p= 0.449 data_size: 10000 10000\n",
      "L= 6 p= 0.516 data_size: 10000 10000\n",
      "L= 6 p= 0.583 data_size: 10000 10000\n",
      "L= 6 p= 0.651 data_size: 10000 10000\n",
      "L= 6 p= 0.718 data_size: 10000 10000\n",
      "L= 6 p= 0.785 data_size: 10000 10000\n",
      "L= 6 p= 0.853 data_size: 10000 10000\n",
      "L= 6 p= 0.92 data_size: 10000 10000\n",
      "L= 6 p= 0.987 data_size: 10000 10000\n",
      "L= 6 p= 1.055 data_size: 10000 10000\n",
      "L= 6 p= 1.122 data_size: 10000 10000\n",
      "L= 6 p= 1.189 data_size: 10000 10000\n",
      "L= 6 p= 1.257 data_size: 10000 10000\n",
      "L= 8 p= 0.07853981633974483 data_size: 10000 10000\n",
      "L= 8 p= 0.15707963267948966 data_size: 10000 10000\n",
      "L= 8 p= 0.23561944901923448 data_size: 10000 10000\n",
      "L= 8 p= 0.314 data_size: 10000 10000\n",
      "L= 8 p= 0.381 data_size: 10000 10000\n",
      "L= 8 p= 0.449 data_size: 10000 10000\n",
      "L= 8 p= 0.516 data_size: 10000 10000\n",
      "L= 8 p= 0.583 data_size: 10000 10000\n",
      "L= 8 p= 0.651 data_size: 10000 10000\n",
      "L= 8 p= 0.718 data_size: 10000 10000\n",
      "L= 8 p= 0.785 data_size: 10000 10000\n",
      "L= 8 p= 0.853 data_size: 10000 10000\n",
      "L= 8 p= 0.92 data_size: 10000 10000\n",
      "L= 8 p= 0.987 data_size: 10000 10000\n",
      "L= 8 p= 1.055 data_size: 10000 10000\n",
      "L= 8 p= 1.122 data_size: 10000 10000\n",
      "L= 8 p= 1.189 data_size: 10000 10000\n",
      "L= 8 p= 1.257 data_size: 10000 10000\n",
      "L= 10 p= 0.07853981633974483 data_size: 10000 10000\n",
      "L= 10 p= 0.15707963267948966 data_size: 10000 10000\n",
      "L= 10 p= 0.23561944901923448 data_size: 10000 10000\n",
      "L= 10 p= 0.314 data_size: 10000 10000\n",
      "L= 10 p= 0.381 data_size: 10000 10000\n",
      "L= 10 p= 0.449 data_size: 10000 10000\n",
      "L= 10 p= 0.516 data_size: 10000 10000\n",
      "L= 10 p= 0.583 data_size: 10000 10000\n",
      "L= 10 p= 0.651 data_size: 10000 10000\n",
      "L= 10 p= 0.718 data_size: 10000 10000\n",
      "L= 10 p= 0.785 data_size: 10000 10000\n",
      "L= 10 p= 0.853 data_size: 10000 10000\n",
      "L= 10 p= 0.92 data_size: 10000 10000\n",
      "L= 10 p= 0.987 data_size: 10000 10000\n",
      "L= 10 p= 1.055 data_size: 10000 10000\n",
      "L= 10 p= 1.122 data_size: 10000 10000\n",
      "L= 10 p= 1.189 data_size: 10000 10000\n",
      "L= 10 p= 1.257 data_size: 10000 10000\n",
      "L= 12 p= 0.07853981633974483 data_size: 10000 10000\n",
      "L= 12 p= 0.15707963267948966 data_size: 10000 10000\n",
      "L= 12 p= 0.23561944901923448 data_size: 10000 10000\n",
      "L= 12 p= 0.314 data_size: 10000 10000\n",
      "L= 12 p= 0.381 data_size: 10000 10000\n",
      "L= 12 p= 0.449 data_size: 10000 10000\n",
      "L= 12 p= 0.516 data_size: 10000 10000\n",
      "L= 12 p= 0.583 data_size: 10000 10000\n",
      "L= 12 p= 0.651 data_size: 10000 10000\n",
      "L= 12 p= 0.718 data_size: 10000 10000\n",
      "L= 12 p= 0.785 data_size: 10000 10000\n",
      "L= 12 p= 0.853 data_size: 10000 10000\n",
      "L= 12 p= 0.92 data_size: 10000 10000\n",
      "L= 12 p= 0.987 data_size: 10000 10000\n",
      "L= 12 p= 1.055 data_size: 10000 10000\n",
      "L= 12 p= 1.122 data_size: 10000 10000\n",
      "L= 12 p= 1.189 data_size: 10000 10000\n",
      "L= 12 p= 1.257 data_size: 10000 10000\n",
      "L= 14 p= 0.07853981633974483 data_size: 10000 10000\n",
      "L= 14 p= 0.15707963267948966 data_size: 10000 10000\n",
      "L= 14 p= 0.23561944901923448 data_size: 10000 10000\n",
      "L= 14 p= 0.314 data_size: 10000 10000\n",
      "L= 14 p= 0.381 data_size: 10000 10000\n",
      "L= 14 p= 0.449 data_size: 10000 10000\n",
      "L= 14 p= 0.516 data_size: 10000 10000\n",
      "L= 14 p= 0.583 data_size: 10000 10000\n",
      "L= 14 p= 0.651 data_size: 10000 10000\n",
      "L= 14 p= 0.718 data_size: 10000 10000\n",
      "L= 14 p= 0.785 data_size: 10000 10000\n",
      "L= 14 p= 0.853 data_size: 10000 10000\n",
      "L= 14 p= 0.92 data_size: 10000 10000\n",
      "L= 14 p= 0.987 data_size: 10000 10000\n",
      "L= 14 p= 1.055 data_size: 10000 10000\n",
      "L= 14 p= 1.122 data_size: 10000 10000\n",
      "L= 14 p= 1.189 data_size: 10000 10000\n",
      "L= 14 p= 1.257 data_size: 10000 10000\n",
      "L= 6 p= 0.07853981633974483 data_size: 10000 10000\n",
      "L= 6 p= 0.15707963267948966 data_size: 10000 10000\n",
      "L= 6 p= 0.23561944901923448 data_size: 10000 10000\n",
      "L= 6 p= 0.314 data_size: 10000 10000\n",
      "L= 6 p= 0.381 data_size: 10000 10000\n",
      "L= 6 p= 0.449 data_size: 10000 10000\n",
      "L= 6 p= 0.516 data_size: 10000 10000\n",
      "L= 6 p= 0.583 data_size: 10000 10000\n",
      "L= 6 p= 0.651 data_size: 10000 10000\n",
      "L= 6 p= 0.718 data_size: 10000 10000\n",
      "L= 6 p= 0.785 data_size: 10000 10000\n",
      "L= 6 p= 0.853 data_size: 10000 10000\n",
      "L= 6 p= 0.92 data_size: 10000 10000\n",
      "L= 6 p= 0.987 data_size: 10000 10000\n",
      "L= 6 p= 1.055 data_size: 10000 10000\n",
      "L= 6 p= 1.122 data_size: 10000 10000\n",
      "L= 6 p= 1.189 data_size: 10000 10000\n",
      "L= 6 p= 1.257 data_size: 10000 10000\n",
      "L= 8 p= 0.07853981633974483 data_size: 10000 10000\n",
      "L= 8 p= 0.15707963267948966 data_size: 10000 10000\n",
      "L= 8 p= 0.23561944901923448 data_size: 10000 10000\n",
      "L= 8 p= 0.314 data_size: 10000 10000\n",
      "L= 8 p= 0.381 data_size: 10000 10000\n",
      "L= 8 p= 0.449 data_size: 10000 10000\n",
      "L= 8 p= 0.516 data_size: 10000 10000\n",
      "L= 8 p= 0.583 data_size: 10000 10000\n",
      "L= 8 p= 0.651 data_size: 10000 10000\n",
      "L= 8 p= 0.718 data_size: 10000 10000\n",
      "L= 8 p= 0.785 data_size: 10000 10000\n",
      "L= 8 p= 0.853 data_size: 10000 10000\n",
      "L= 8 p= 0.92 data_size: 10000 10000\n",
      "L= 8 p= 0.987 data_size: 10000 10000\n",
      "L= 8 p= 1.055 data_size: 10000 10000\n",
      "L= 8 p= 1.122 data_size: 10000 10000\n",
      "L= 8 p= 1.189 data_size: 10000 10000\n",
      "L= 8 p= 1.257 data_size: 10000 10000\n",
      "L= 10 p= 0.07853981633974483 data_size: 10000 10000\n",
      "L= 10 p= 0.15707963267948966 data_size: 10000 10000\n",
      "L= 10 p= 0.23561944901923448 data_size: 10000 10000\n",
      "L= 10 p= 0.314 data_size: 10000 10000\n",
      "L= 10 p= 0.381 data_size: 10000 10000\n",
      "L= 10 p= 0.449 data_size: 10000 10000\n",
      "L= 10 p= 0.516 data_size: 10000 10000\n",
      "L= 10 p= 0.583 data_size: 10000 10000\n",
      "L= 10 p= 0.651 data_size: 10000 10000\n",
      "L= 10 p= 0.718 data_size: 10000 10000\n",
      "L= 10 p= 0.785 data_size: 10000 10000\n",
      "L= 10 p= 0.853 data_size: 10000 10000\n",
      "L= 10 p= 0.92 data_size: 10000 10000\n",
      "L= 10 p= 0.987 data_size: 10000 10000\n",
      "L= 10 p= 1.055 data_size: 10000 10000\n",
      "L= 10 p= 1.122 data_size: 10000 10000\n",
      "L= 10 p= 1.189 data_size: 10000 10000\n",
      "L= 10 p= 1.257 data_size: 10000 10000\n",
      "L= 12 p= 0.07853981633974483 data_size: 10000 10000\n",
      "L= 12 p= 0.15707963267948966 data_size: 10000 10000\n",
      "L= 12 p= 0.23561944901923448 data_size: 10000 10000\n",
      "L= 12 p= 0.314 data_size: 10000 10000\n",
      "L= 12 p= 0.381 data_size: 10000 10000\n",
      "L= 12 p= 0.449 data_size: 10000 10000\n",
      "L= 12 p= 0.516 data_size: 10000 10000\n",
      "L= 12 p= 0.583 data_size: 10000 10000\n",
      "L= 12 p= 0.651 data_size: 10000 10000\n",
      "L= 12 p= 0.718 data_size: 10000 10000\n",
      "L= 12 p= 0.785 data_size: 10000 10000\n",
      "L= 12 p= 0.853 data_size: 10000 10000\n",
      "L= 12 p= 0.92 data_size: 10000 10000\n",
      "L= 12 p= 0.987 data_size: 10000 10000\n",
      "L= 12 p= 1.055 data_size: 10000 10000\n",
      "L= 12 p= 1.122 data_size: 10000 10000\n",
      "L= 12 p= 1.189 data_size: 10000 10000\n",
      "L= 12 p= 1.257 data_size: 10000 10000\n",
      "L= 14 p= 0.07853981633974483 data_size: 10000 10000\n",
      "L= 14 p= 0.15707963267948966 data_size: 10000 10000\n",
      "L= 14 p= 0.23561944901923448 data_size: 10000 10000\n",
      "L= 14 p= 0.314 data_size: 10000 10000\n",
      "L= 14 p= 0.381 data_size: 10000 10000\n",
      "L= 14 p= 0.449 data_size: 10000 10000\n",
      "L= 14 p= 0.516 data_size: 10000 10000\n",
      "L= 14 p= 0.583 data_size: 10000 10000\n",
      "L= 14 p= 0.651 data_size: 10000 10000\n",
      "L= 14 p= 0.718 data_size: 10000 10000\n",
      "L= 14 p= 0.785 data_size: 10000 10000\n",
      "L= 14 p= 0.853 data_size: 10000 10000\n",
      "L= 14 p= 0.92 data_size: 10000 10000\n",
      "L= 14 p= 0.987 data_size: 10000 10000\n",
      "L= 14 p= 1.055 data_size: 10000 10000\n",
      "L= 14 p= 1.122 data_size: 10000 10000\n",
      "L= 14 p= 1.189 data_size: 10000 10000\n",
      "L= 14 p= 1.257 data_size: 10000 10000\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'get_RNN_simulation_data_suc_prob' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/utkarshagrawal/Documents/Postdoc/U_1_exp/Weak measurements/analyze_data copy.ipynb Cell 21\u001b[0m in \u001b[0;36m<cell line: 78>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/utkarshagrawal/Documents/Postdoc/U_1_exp/Weak%20measurements/analyze_data%20copy.ipynb#X26sZmlsZQ%3D%3D?line=85'>86</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/utkarshagrawal/Documents/Postdoc/U_1_exp/Weak%20measurements/analyze_data%20copy.ipynb#X26sZmlsZQ%3D%3D?line=86'>87</a>\u001b[0m     \u001b[39mif\u001b[39;00m plot_suc:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/utkarshagrawal/Documents/Postdoc/U_1_exp/Weak%20measurements/analyze_data%20copy.ipynb#X26sZmlsZQ%3D%3D?line=87'>88</a>\u001b[0m         xdata,ydata,yerr \u001b[39m=\u001b[39m get_RNN_simulation_data_suc_prob(L,\u001b[39msorted\u001b[39m(p_select))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/utkarshagrawal/Documents/Postdoc/U_1_exp/Weak%20measurements/analyze_data%20copy.ipynb#X26sZmlsZQ%3D%3D?line=88'>89</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/utkarshagrawal/Documents/Postdoc/U_1_exp/Weak%20measurements/analyze_data%20copy.ipynb#X26sZmlsZQ%3D%3D?line=89'>90</a>\u001b[0m         xdata,ydata,yerr \u001b[39m=\u001b[39m get_RNN_simulation_data_acc(L,\u001b[39msorted\u001b[39m(p_select))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_RNN_simulation_data_suc_prob' is not defined"
     ]
    }
   ],
   "source": [
    "# %matplotlib qt\n",
    "fig,ax = pl.subplots(1,figsize=(6,5))\n",
    "L_list = [6,8,10,12,14,16][:5]\n",
    "# L_list = [6,10,14]\n",
    "\n",
    "colors = pl.cm.Blues(np.linspace(0.5,1,len(L_list)))\n",
    "\n",
    "\n",
    "depth_ratio=0.5\n",
    "if depth_ratio != 1:\n",
    "    depth_label = '_depth_ratio='+str(depth_ratio) + '/'\n",
    "else:\n",
    "    depth_label = '/'\n",
    "\n",
    "\n",
    "quantinuum = True\n",
    "ROOT_DIREC_Q = '../Quantinum/Weak measurements/data/hardware_data/'\n",
    "p_select_Q = [0.079,0.236,0.516,0.785,0.92,1.122]\n",
    "    \n",
    "ROOT_DIREC = 'data/' #simulation data directory\n",
    "\n",
    "p_list = list(np.round(np.linspace(0.2*np.pi/2,0.8*np.pi/2,15),3))\n",
    "p_list.extend(list(np.array([0.001,0.01,0.02,0.05,0.1,0.15])*np.pi/2))\n",
    "p_list = sorted(p_list)\n",
    "\n",
    "# p_select is a list of p values we want to plot\n",
    "p_select = np.array([0.07853981633974483,0.23561944901923448 ,0.516,0.785,0.92,1.122]) # p values ran on hardware\n",
    "p_select = [p_list[0]] + p_list[3:]\n",
    "\n",
    "is_noisy = '_noisy'\n",
    "decoding_label = '_decoding_protocol='+str(3)\n",
    "\n",
    "#_large label is for simulation data with 10000 samples\n",
    "\n",
    "file_large = './large_scale_data/sep_seed=1_all_qubits_special_scrambled'\n",
    "\n",
    "file2_Q = ROOT_DIREC_Q+'biased_sep_data_neel'+depth_label+'seed=1_all_qubits_special_scrambled'+decoding_label+is_noisy\n",
    "file2_large = 'large_scale_data/biased_sep_seed=1_all_qubits_special_scrambled'\n",
    "\n",
    "file3_Q = ROOT_DIREC_Q+'quantum_decoder_neel'+depth_label+'/seed=1_all_qubits_special_scrambled'+decoding_label+is_noisy\n",
    "file3_large = 'large_scale_data/quantum_decoder_seed=1_all_qubits_special_scrambled'\n",
    "\n",
    "data = load_data(file_large)\n",
    "data2 = load_data(file2_large)\n",
    "data3 = load_data(file3_large)\n",
    "\n",
    "#Hardware date\n",
    "data2_Q = load_data(file2_Q)\n",
    "data3_Q = load_data(file3_Q)\n",
    "\n",
    "data_list = [data2,data3]\n",
    "temp_quan = [0,0]\n",
    "\n",
    "plot_quantum_data = False\n",
    "\n",
    "plot_suc = True\n",
    "\n",
    "if plot_quantum_data:\n",
    "    p_select = p_select_Q\n",
    "    data_list = [data2_Q,data3_Q]\n",
    "    temp_quan = [0,1] #temp_quan = 1 for quantum decoder data on hardware. The quantum data has a different data structure\n",
    "\n",
    "lss = ['-',':']\n",
    "lw = 2\n",
    "for i,dat in enumerate(data_list):\n",
    "    if not plot_suc:\n",
    "        acc,err,_,_ = get_acc_data(dat,L_list,temp_quan=temp_quan[i],p_selected=p_select) #use get_suc_prob_data for suc_prob\n",
    "    else:\n",
    "        acc,err,_,_ = get_suc_prob_data(dat,L_list,temp_quan=temp_quan[i],p_selected=p_select)\n",
    "    for j,L in enumerate(L_list):\n",
    "        xdata = np.array(sorted(list(acc[L].keys())))\n",
    "        ydata = np.array([acc[L][p] for p in xdata])\n",
    "        errdata = np.array([err[L][p] for p in xdata])\n",
    "\n",
    "        ax.errorbar(xdata*2/np.pi,ydata,yerr=errdata,ls=lss[i],marker='o',ms=6,color=colors[j],lw=lw)\n",
    "\n",
    "\n",
    "for i,L in enumerate(L_list):\n",
    "        # use get_RNN_hardware_data_suc_prob for suc_prob\n",
    "\n",
    "        if plot_quantum_data:\n",
    "            if plot_suc:\n",
    "                xdata,ydata,yerr = get_RNN_hardware_data_suc_prob(L,p_select)\n",
    "            else:\n",
    "                xdata,ydata,yerr = get_RNN_hardware_data_acc(L,p_select)\n",
    "        else:\n",
    "            if plot_suc:\n",
    "                xdata,ydata,yerr = get_RNN_simulation_data_suc_prob(L,sorted(p_select))\n",
    "            else:\n",
    "                xdata,ydata,yerr = get_RNN_simulation_data_acc(L,sorted(p_select))\n",
    "        ax.errorbar([p*2/np.pi for p in xdata],ydata,yerr=yerr,ls='--',marker='o',color=colors[i],lw=lw)\n",
    "        continue\n",
    "\n",
    "# RNN_plot(L_list,p_select_Q)\n",
    "\n",
    "pl.plot([],[],'-',color='k',label='Stat-mech')\n",
    "pl.plot([],[],'--',color='k',label='RNN')\n",
    "pl.plot([],[],':',color='k',label='PostBQP')\n",
    "\n",
    "[ax.plot([],[],'-',label=r'$L=$'+str(L)) for L in L_list]\n",
    "\n",
    "ax.tick_params(axis='both', which='major', labelsize=14)\n",
    "ax.tick_params(axis='both', which='major', labelsize=14)\n",
    "\n",
    "label_size = 16\n",
    "\n",
    "if plot_suc:\n",
    "    ax.set_ylabel(r'Credence $C$',fontsize=label_size)\n",
    "else:\n",
    "    ax.set_ylabel(r'Accuracy $\\alpha$',fontsize=label_size)\n",
    "\n",
    "\n",
    "ax.set_xlabel(r'$\\gamma$',fontsize=label_size)\n",
    "\n",
    "\n",
    "ax.legend(fontsize=12)\n",
    "\n",
    "fig.set_tight_layout(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L= 6 p= 0.07853981633974483 data_size: 10000 10000\n",
      "L= 6 p= 0.15707963267948966 data_size: 10000 10000\n",
      "L= 6 p= 0.23561944901923448 data_size: 10000 10000\n",
      "L= 6 p= 0.314 data_size: 10000 10000\n",
      "L= 6 p= 0.381 data_size: 10000 10000\n",
      "L= 6 p= 0.449 data_size: 10000 10000\n",
      "L= 6 p= 0.516 data_size: 10000 10000\n",
      "L= 6 p= 0.583 data_size: 10000 10000\n",
      "L= 6 p= 0.651 data_size: 10000 10000\n",
      "L= 6 p= 0.718 data_size: 10000 10000\n",
      "L= 6 p= 0.785 data_size: 10000 10000\n",
      "L= 6 p= 0.853 data_size: 10000 10000\n",
      "L= 6 p= 0.92 data_size: 10000 10000\n",
      "L= 6 p= 0.987 data_size: 10000 10000\n",
      "L= 6 p= 1.055 data_size: 10000 10000\n",
      "L= 6 p= 1.122 data_size: 10000 10000\n",
      "L= 6 p= 1.189 data_size: 10000 10000\n",
      "L= 6 p= 1.257 data_size: 10000 10000\n",
      "L= 10 p= 0.07853981633974483 data_size: 10000 10000\n",
      "L= 10 p= 0.15707963267948966 data_size: 10000 10000\n",
      "L= 10 p= 0.23561944901923448 data_size: 10000 10000\n",
      "L= 10 p= 0.314 data_size: 10000 10000\n",
      "L= 10 p= 0.381 data_size: 10000 10000\n",
      "L= 10 p= 0.449 data_size: 10000 10000\n",
      "L= 10 p= 0.516 data_size: 10000 10000\n",
      "L= 10 p= 0.583 data_size: 10000 10000\n",
      "L= 10 p= 0.651 data_size: 10000 10000\n",
      "L= 10 p= 0.718 data_size: 10000 10000\n",
      "L= 10 p= 0.785 data_size: 10000 10000\n",
      "L= 10 p= 0.853 data_size: 10000 10000\n",
      "L= 10 p= 0.92 data_size: 10000 10000\n",
      "L= 10 p= 0.987 data_size: 10000 10000\n",
      "L= 10 p= 1.055 data_size: 10000 10000\n",
      "L= 10 p= 1.122 data_size: 10000 10000\n",
      "L= 10 p= 1.189 data_size: 10000 10000\n",
      "L= 10 p= 1.257 data_size: 10000 10000\n",
      "L= 14 p= 0.07853981633974483 data_size: 10000 10000\n",
      "L= 14 p= 0.15707963267948966 data_size: 10000 10000\n",
      "L= 14 p= 0.23561944901923448 data_size: 10000 10000\n",
      "L= 14 p= 0.314 data_size: 10000 10000\n",
      "L= 14 p= 0.381 data_size: 10000 10000\n",
      "L= 14 p= 0.449 data_size: 10000 10000\n",
      "L= 14 p= 0.516 data_size: 10000 10000\n",
      "L= 14 p= 0.583 data_size: 10000 10000\n",
      "L= 14 p= 0.651 data_size: 10000 10000\n",
      "L= 14 p= 0.718 data_size: 10000 10000\n",
      "L= 14 p= 0.785 data_size: 10000 10000\n",
      "L= 14 p= 0.853 data_size: 10000 10000\n",
      "L= 14 p= 0.92 data_size: 10000 10000\n",
      "L= 14 p= 0.987 data_size: 10000 10000\n",
      "L= 14 p= 1.055 data_size: 10000 10000\n",
      "L= 14 p= 1.122 data_size: 10000 10000\n",
      "L= 14 p= 1.189 data_size: 10000 10000\n",
      "L= 14 p= 1.257 data_size: 10000 10000\n",
      "L= 6 p= 0.079 data_size: 181 173\n",
      "L= 6 p= 0.236 data_size: 183 180\n",
      "L= 6 p= 0.516 data_size: 188 182\n",
      "L= 6 p= 0.785 data_size: 187 179\n",
      "L= 6 p= 0.92 data_size: 84 79\n",
      "L= 6 p= 1.122 data_size: 174 168\n",
      "L= 10 p= 0.079 data_size: 64 67\n",
      "L= 10 p= 0.236 data_size: 136 118\n",
      "L= 10 p= 0.516 data_size: 128 119\n",
      "L= 10 p= 0.785 data_size: 206 187\n",
      "L= 10 p= 0.92 data_size: 442 384\n",
      "L= 10 p= 1.122 data_size: 125 120\n",
      "L= 14 p= 0.236 data_size: 164 179\n",
      "L= 14 p= 0.516 data_size: 158 148\n",
      "L= 14 p= 0.785 data_size: 232 177\n",
      "L= 14 p= 0.92 data_size: 266 253\n",
      "L= 14 p= 1.122 data_size: 73 61\n"
     ]
    }
   ],
   "source": [
    "L_list = [6,8,10,12,14,16][:5]\n",
    "L_list = [6,10,14]\n",
    "\n",
    "depth_ratio=0.5\n",
    "if depth_ratio != 1:\n",
    "    depth_label = '_depth_ratio='+str(depth_ratio) + '/'\n",
    "else:\n",
    "    depth_label = '/'\n",
    "\n",
    "fig,axs = pl.subplots(1,2,figsize=(11,5))\n",
    "\n",
    "quantinuum = True\n",
    "ROOT_DIREC_Q = '../Quantinum/Weak measurements/data/hardware_data/'\n",
    "p_select_Q = [0.079,0.236,0.516,0.785,0.92,1.122]\n",
    "    \n",
    "ROOT_DIREC = 'data/'\n",
    "p_select = np.array([0.07853981633974483,0.23561944901923448 ,0.516,0.785,0.92,1.122])\n",
    "is_noisy = '_noisy'\n",
    "decoding_label_3 = '_decoding_protocol='+str(3)\n",
    "decoding_label_0 = '_decoding_protocol='+str(0)\n",
    "\n",
    "file_large = 'large_scale_data/biased_sep_seed=1_all_qubits_special_scrambled'\n",
    "file = ROOT_DIREC+'sep_data_neel'+depth_label+'seed=1_all_qubits_special_scrambled'+decoding_label_3+is_noisy\n",
    "\n",
    "file2 = ROOT_DIREC+'biased_sep_data_neel'+depth_label+'seed=1_all_qubits_special_scrambled'+decoding_label_3+is_noisy\n",
    "file2_Q = ROOT_DIREC_Q+'biased_sep_data_neel'+depth_label+'seed=1_all_qubits_special_scrambled'+decoding_label_3+is_noisy\n",
    "\n",
    "file3 = ROOT_DIREC + 'quantum_decoder_neel'+depth_label+'/seed=1_all_qubits_special_scrambled'\n",
    "file3_Q = ROOT_DIREC_Q+'quantum_decoder_neel'+depth_label+'/seed=1_all_qubits_special_scrambled'+decoding_label_3+is_noisy\n",
    "      \n",
    "data2_Q = load_data(file2_Q)\n",
    "data2 = load_data(file_large)\n",
    "\n",
    "\n",
    "suc_prob_sim, err_sim, var_sim, var_err_sim = get_suc_prob_data(data2,L_list,temp_quan=0,p_selected=[])\n",
    "suc_prob_exp, err_exp, var_exp, var_err_exp = get_suc_prob_data(data2_Q,L_list,temp_quan=0,p_selected=[])\n",
    "\n",
    "\n",
    "\n",
    "lw = 3 \n",
    "for i,L in enumerate(L_list):\n",
    "    p_data_sim = np.array(sorted(list(suc_prob_sim[L].keys())))\n",
    "    ydata_sim = [suc_prob_sim[L][p] for p in p_data_sim]\n",
    "    errdata_sim = [err_sim[L][p] for p in p_data_sim]\n",
    "    var_ydata_sim = [var_sim[L][p] for p in p_data_sim]\n",
    "    var_errdata_sim = [var_err_sim[L][p] for p in p_data_sim]\n",
    "\n",
    "    p_data_exp = np.array(sorted(list(suc_prob_exp[L].keys())))\n",
    "    ydata_exp = [suc_prob_exp[L][p] for p in p_data_exp]\n",
    "    errdata_exp = [err_exp[L][p] for p in p_data_exp]\n",
    "    var_ydata_exp = [var_exp[L][p] for p in p_data_exp]\n",
    "    var_errdata_exp = [var_err_exp[L][p] for p in p_data_exp]\n",
    "\n",
    "    axs[0].errorbar(p_data_sim/(np.pi/2),ydata_sim,yerr=errdata_sim,marker='o',ls=':',color=colors[i],ms=3,alpha=0.6,lw=2)\n",
    "\n",
    "    axs[0].errorbar(p_data_exp/(np.pi/2),ydata_exp,yerr=errdata_exp,marker='o',ls='-',color=colors[i],ms=6,alpha=1,lw=lw)\n",
    "\n",
    "    axs[1].errorbar(p_data_sim/(np.pi/2),var_ydata_sim,yerr=var_errdata_sim,marker='o',ls=':',color=colors[i],ms=3,alpha=0.4)\n",
    "\n",
    "    axs[1].errorbar(p_data_exp/(np.pi/2),var_ydata_exp,yerr=var_errdata_exp,marker='o',ls='-',color=colors[i],ms=6,alpha=1,lw=lw)\n",
    "\n",
    "\n",
    "\n",
    "axs[0].errorbar([],[],[],ls='-',marker='o',ms=6,color='k',label='Experiment')\n",
    "axs[0].errorbar([],[],[],ls=':',marker='o',ms=3,color='k',label='Noiseless Simulation')\n",
    "# [pl.plot([],[],'-',label=r'$L=$'+str(L)) for L in L_list]\n",
    "\n",
    "axs[0].tick_params(axis='both', which='major', labelsize=14)\n",
    "axs[1].tick_params(axis='both', which='major', labelsize=14)\n",
    "\n",
    "label_size = 16\n",
    "\n",
    "axs[0].set_ylabel(r'Credence $C$',fontsize=label_size)\n",
    "axs[1].set_ylabel(r'Variance of $C$',fontsize=label_size)\n",
    "\n",
    "axs[0].set_xlabel(r'$\\gamma$',fontsize=label_size)\n",
    "axs[1].set_xlabel(r'$\\gamma$',fontsize=label_size)\n",
    "\n",
    "axs[0].legend(fontsize=12)\n",
    "\n",
    "fig.set_tight_layout(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sim data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L= 6 p= 0.07853981633974483 data_size: 10000 10000\n",
      "L= 6 p= 0.15707963267948966 data_size: 10000 10000\n",
      "L= 6 p= 0.23561944901923448 data_size: 10000 10000\n",
      "L= 6 p= 0.314 data_size: 10000 10000\n",
      "L= 6 p= 0.381 data_size: 10000 10000\n",
      "L= 6 p= 0.449 data_size: 10000 10000\n",
      "L= 6 p= 0.516 data_size: 10000 10000\n",
      "L= 6 p= 0.583 data_size: 10000 10000\n",
      "L= 6 p= 0.651 data_size: 10000 10000\n",
      "L= 6 p= 0.718 data_size: 10000 10000\n",
      "L= 6 p= 0.785 data_size: 10000 10000\n",
      "L= 6 p= 0.853 data_size: 10000 10000\n",
      "L= 6 p= 0.92 data_size: 10000 10000\n",
      "L= 6 p= 0.987 data_size: 10000 10000\n",
      "L= 6 p= 1.055 data_size: 10000 10000\n",
      "L= 6 p= 1.122 data_size: 10000 10000\n",
      "L= 6 p= 1.189 data_size: 10000 10000\n",
      "L= 6 p= 1.257 data_size: 10000 10000\n",
      "L= 8 p= 0.07853981633974483 data_size: 10000 10000\n",
      "L= 8 p= 0.15707963267948966 data_size: 10000 10000\n",
      "L= 8 p= 0.23561944901923448 data_size: 10000 10000\n",
      "L= 8 p= 0.314 data_size: 10000 10000\n",
      "L= 8 p= 0.381 data_size: 10000 10000\n",
      "L= 8 p= 0.449 data_size: 10000 10000\n",
      "L= 8 p= 0.516 data_size: 10000 10000\n",
      "L= 8 p= 0.583 data_size: 10000 10000\n",
      "L= 8 p= 0.651 data_size: 10000 10000\n",
      "L= 8 p= 0.718 data_size: 10000 10000\n",
      "L= 8 p= 0.785 data_size: 10000 10000\n",
      "L= 8 p= 0.853 data_size: 10000 10000\n",
      "L= 8 p= 0.92 data_size: 10000 10000\n",
      "L= 8 p= 0.987 data_size: 10000 10000\n",
      "L= 8 p= 1.055 data_size: 10000 10000\n",
      "L= 8 p= 1.122 data_size: 10000 10000\n",
      "L= 8 p= 1.189 data_size: 10000 10000\n",
      "L= 8 p= 1.257 data_size: 10000 10000\n",
      "L= 10 p= 0.07853981633974483 data_size: 10000 10000\n",
      "L= 10 p= 0.15707963267948966 data_size: 10000 10000\n",
      "L= 10 p= 0.23561944901923448 data_size: 10000 10000\n",
      "L= 10 p= 0.314 data_size: 10000 10000\n",
      "L= 10 p= 0.381 data_size: 10000 10000\n",
      "L= 10 p= 0.449 data_size: 10000 10000\n",
      "L= 10 p= 0.516 data_size: 10000 10000\n",
      "L= 10 p= 0.583 data_size: 10000 10000\n",
      "L= 10 p= 0.651 data_size: 10000 10000\n",
      "L= 10 p= 0.718 data_size: 10000 10000\n",
      "L= 10 p= 0.785 data_size: 10000 10000\n",
      "L= 10 p= 0.853 data_size: 10000 10000\n",
      "L= 10 p= 0.92 data_size: 10000 10000\n",
      "L= 10 p= 0.987 data_size: 10000 10000\n",
      "L= 10 p= 1.055 data_size: 10000 10000\n",
      "L= 10 p= 1.122 data_size: 10000 10000\n",
      "L= 10 p= 1.189 data_size: 10000 10000\n",
      "L= 10 p= 1.257 data_size: 10000 10000\n",
      "L= 12 p= 0.07853981633974483 data_size: 10000 10000\n",
      "L= 12 p= 0.15707963267948966 data_size: 10000 10000\n",
      "L= 12 p= 0.23561944901923448 data_size: 10000 10000\n",
      "L= 12 p= 0.314 data_size: 10000 10000\n",
      "L= 12 p= 0.381 data_size: 10000 10000\n",
      "L= 12 p= 0.449 data_size: 10000 10000\n",
      "L= 12 p= 0.516 data_size: 10000 10000\n",
      "L= 12 p= 0.583 data_size: 10000 10000\n",
      "L= 12 p= 0.651 data_size: 10000 10000\n",
      "L= 12 p= 0.718 data_size: 10000 10000\n",
      "L= 12 p= 0.785 data_size: 10000 10000\n",
      "L= 12 p= 0.853 data_size: 10000 10000\n",
      "L= 12 p= 0.92 data_size: 10000 10000\n",
      "L= 12 p= 0.987 data_size: 10000 10000\n",
      "L= 12 p= 1.055 data_size: 10000 10000\n",
      "L= 12 p= 1.122 data_size: 10000 10000\n",
      "L= 12 p= 1.189 data_size: 10000 10000\n",
      "L= 12 p= 1.257 data_size: 10000 10000\n",
      "L= 14 p= 0.07853981633974483 data_size: 10000 10000\n",
      "L= 14 p= 0.15707963267948966 data_size: 10000 10000\n",
      "L= 14 p= 0.23561944901923448 data_size: 10000 10000\n",
      "L= 14 p= 0.314 data_size: 10000 10000\n",
      "L= 14 p= 0.381 data_size: 10000 10000\n",
      "L= 14 p= 0.449 data_size: 10000 10000\n",
      "L= 14 p= 0.516 data_size: 10000 10000\n",
      "L= 14 p= 0.583 data_size: 10000 10000\n",
      "L= 14 p= 0.651 data_size: 10000 10000\n",
      "L= 14 p= 0.718 data_size: 10000 10000\n",
      "L= 14 p= 0.785 data_size: 10000 10000\n",
      "L= 14 p= 0.853 data_size: 10000 10000\n",
      "L= 14 p= 0.92 data_size: 10000 10000\n",
      "L= 14 p= 0.987 data_size: 10000 10000\n",
      "L= 14 p= 1.055 data_size: 10000 10000\n",
      "L= 14 p= 1.122 data_size: 10000 10000\n",
      "L= 14 p= 1.189 data_size: 10000 10000\n",
      "L= 14 p= 1.257 data_size: 10000 10000\n"
     ]
    }
   ],
   "source": [
    "L_list = [6,8,10,12,14,16][:5]\n",
    "\n",
    "colors = pl.cm.Blues(np.linspace(0.5,1,len(L_list)))\n",
    "\n",
    "depth_ratio=0.5\n",
    "if depth_ratio != 1:\n",
    "    depth_label = '_depth_ratio='+str(depth_ratio) + '/'\n",
    "else:\n",
    "    depth_label = '/'\n",
    "\n",
    "fig,axs = pl.subplots(1,2,figsize=(11,5))\n",
    "\n",
    "\n",
    "    \n",
    "ROOT_DIREC = 'data/'\n",
    "# p_select = np.array([0.07853981633974483,0.23561944901923448 ,0.516,0.785,0.92,1.122])\n",
    "is_noisy = ''\n",
    "# decoding_label_3 = '_decoding_protocol='+str(3)\n",
    "decoding_label_0 = '_decoding_protocol='+str(0)\n",
    "\n",
    "file_large = 'large_scale_data/biased_sep_seed=1_all_qubits_special_scrambled'\n",
    "\n",
    "# file_large = 'large_scale_data/quantum_decoder_seed=1_all_qubits_special_scrambled'\n",
    "\n",
    "\n",
    "      \n",
    "\n",
    "\n",
    "\n",
    "RNN = False\n",
    "lw = 3\n",
    "ms=6 \n",
    "if not RNN:\n",
    "    data2 = load_data(file_large)\n",
    "\n",
    "    suc_prob_sim, err_sim, var_sim, var_err_sim = get_suc_prob_data(data2,L_list,temp_quan=0,p_selected=[])\n",
    "    for i,L in enumerate(L_list):\n",
    "        p_data_sim = np.array(sorted(list(suc_prob_sim[L].keys())))\n",
    "        ydata_sim = [suc_prob_sim[L][p] for p in p_data_sim]\n",
    "        errdata_sim = [err_sim[L][p] for p in p_data_sim]\n",
    "        var_ydata_sim = [var_sim[L][p] for p in p_data_sim]\n",
    "        var_errdata_sim = [var_err_sim[L][p] for p in p_data_sim]\n",
    "\n",
    "\n",
    "        axs[0].errorbar(p_data_sim/(np.pi/2),ydata_sim,yerr=errdata_sim,marker='o',ls='-',color=colors[i],ms=ms,alpha=1,lw=lw,label=r'$L={}$'.format(L))\n",
    "\n",
    "\n",
    "        axs[1].errorbar(p_data_sim/(np.pi/2),var_ydata_sim,yerr=var_errdata_sim,marker='o',ls='-',color=colors[i],ms=ms,alpha=1,lw=lw)\n",
    "\n",
    "\n",
    "if RNN:\n",
    "    for i,L in enumerate(L_list):\n",
    "        p_data_sim,ydata_sim,var_ydata_sim = get_RNN_simulation_data_suc_prob(L,sorted(p_select))\n",
    "        p_data_sim = np.array(p_data_sim)\n",
    "        axs[0].plot(p_data_sim/(np.pi/2),ydata_sim,marker='o',ls='-',color=colors[i],ms=ms,alpha=1,lw=lw,label=r'$L={}$'.format(L))\n",
    "\n",
    "\n",
    "        axs[1].plot(p_data_sim/(np.pi/2),var_ydata_sim,marker='o',ls='-',color=colors[i],ms=ms,alpha=1,lw=lw)\n",
    "\n",
    "# [pl.plot([],[],'-',label=r'$L=$'+str(L)) for L in L_list]\n",
    "\n",
    "axs[0].tick_params(axis='both', which='major', labelsize=14)\n",
    "axs[1].tick_params(axis='both', which='major', labelsize=14)\n",
    "\n",
    "label_size = 16\n",
    "\n",
    "axs[0].set_ylabel(r'Credence $C$',fontsize=label_size)\n",
    "axs[1].set_ylabel(r'Variance of $C$',fontsize=label_size)\n",
    "\n",
    "axs[0].set_xlabel(r'$\\gamma$',fontsize=label_size)\n",
    "axs[1].set_xlabel(r'$\\gamma$',fontsize=label_size)\n",
    "\n",
    "axs[0].legend(fontsize=12)\n",
    "\n",
    "fig.set_tight_layout(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ancilla data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L= 6 p= 0.07853981633974483 data_size: 10000 10000\n",
      "L= 6 p= 0.15707963267948966 data_size: 10000 10000\n",
      "L= 6 p= 0.23561944901923448 data_size: 10000 10000\n",
      "L= 6 p= 0.314 data_size: 10000 10000\n",
      "L= 6 p= 0.381 data_size: 10000 10000\n",
      "L= 6 p= 0.449 data_size: 10000 10000\n",
      "L= 6 p= 0.516 data_size: 10000 10000\n",
      "L= 6 p= 0.583 data_size: 10000 10000\n",
      "L= 6 p= 0.651 data_size: 10000 10000\n",
      "L= 6 p= 0.718 data_size: 10000 10000\n",
      "L= 6 p= 0.785 data_size: 10000 10000\n",
      "L= 6 p= 0.853 data_size: 10000 10000\n",
      "L= 6 p= 0.92 data_size: 10000 10000\n",
      "L= 6 p= 0.987 data_size: 10000 10000\n",
      "L= 6 p= 1.055 data_size: 10000 10000\n",
      "L= 6 p= 1.122 data_size: 10000 10000\n",
      "L= 6 p= 1.189 data_size: 10000 10000\n",
      "L= 6 p= 1.257 data_size: 10000 10000\n",
      "L= 8 p= 0.07853981633974483 data_size: 10000 10000\n",
      "L= 8 p= 0.15707963267948966 data_size: 10000 10000\n",
      "L= 8 p= 0.23561944901923448 data_size: 10000 10000\n",
      "L= 8 p= 0.314 data_size: 10000 10000\n",
      "L= 8 p= 0.381 data_size: 10000 10000\n",
      "L= 8 p= 0.449 data_size: 10000 10000\n",
      "L= 8 p= 0.516 data_size: 10000 10000\n",
      "L= 8 p= 0.583 data_size: 10000 10000\n",
      "L= 8 p= 0.651 data_size: 10000 10000\n",
      "L= 8 p= 0.718 data_size: 10000 10000\n",
      "L= 8 p= 0.785 data_size: 10000 10000\n",
      "L= 8 p= 0.853 data_size: 10000 10000\n",
      "L= 8 p= 0.92 data_size: 10000 10000\n",
      "L= 8 p= 0.987 data_size: 10000 10000\n",
      "L= 8 p= 1.055 data_size: 10000 10000\n",
      "L= 8 p= 1.122 data_size: 10000 10000\n",
      "L= 8 p= 1.189 data_size: 10000 10000\n",
      "L= 8 p= 1.257 data_size: 10000 10000\n",
      "L= 10 p= 0.07853981633974483 data_size: 10000 10000\n",
      "L= 10 p= 0.15707963267948966 data_size: 10000 10000\n",
      "L= 10 p= 0.23561944901923448 data_size: 10000 10000\n",
      "L= 10 p= 0.314 data_size: 10000 10000\n",
      "L= 10 p= 0.381 data_size: 10000 10000\n",
      "L= 10 p= 0.449 data_size: 10000 10000\n",
      "L= 10 p= 0.516 data_size: 10000 10000\n",
      "L= 10 p= 0.583 data_size: 10000 10000\n",
      "L= 10 p= 0.651 data_size: 10000 10000\n",
      "L= 10 p= 0.718 data_size: 10000 10000\n",
      "L= 10 p= 0.785 data_size: 10000 10000\n",
      "L= 10 p= 0.853 data_size: 10000 10000\n",
      "L= 10 p= 0.92 data_size: 10000 10000\n",
      "L= 10 p= 0.987 data_size: 10000 10000\n",
      "L= 10 p= 1.055 data_size: 10000 10000\n",
      "L= 10 p= 1.122 data_size: 10000 10000\n",
      "L= 10 p= 1.189 data_size: 10000 10000\n",
      "L= 10 p= 1.257 data_size: 10000 10000\n",
      "L= 12 p= 0.07853981633974483 data_size: 10000 10000\n",
      "L= 12 p= 0.15707963267948966 data_size: 10000 10000\n",
      "L= 12 p= 0.23561944901923448 data_size: 10000 10000\n",
      "L= 12 p= 0.314 data_size: 10000 10000\n",
      "L= 12 p= 0.381 data_size: 10000 10000\n",
      "L= 12 p= 0.449 data_size: 10000 10000\n",
      "L= 12 p= 0.516 data_size: 10000 10000\n",
      "L= 12 p= 0.583 data_size: 10000 10000\n",
      "L= 12 p= 0.651 data_size: 10000 10000\n",
      "L= 12 p= 0.718 data_size: 10000 10000\n",
      "L= 12 p= 0.785 data_size: 10000 10000\n",
      "L= 12 p= 0.853 data_size: 10000 10000\n",
      "L= 12 p= 0.92 data_size: 10000 10000\n",
      "L= 12 p= 0.987 data_size: 10000 10000\n",
      "L= 12 p= 1.055 data_size: 10000 10000\n",
      "L= 12 p= 1.122 data_size: 10000 10000\n",
      "L= 12 p= 1.189 data_size: 10000 10000\n",
      "L= 12 p= 1.257 data_size: 10000 10000\n",
      "L= 14 p= 0.07853981633974483 data_size: 10000 10000\n",
      "L= 14 p= 0.15707963267948966 data_size: 10000 10000\n",
      "L= 14 p= 0.23561944901923448 data_size: 10000 10000\n",
      "L= 14 p= 0.314 data_size: 10000 10000\n",
      "L= 14 p= 0.381 data_size: 10000 10000\n",
      "L= 14 p= 0.449 data_size: 10000 10000\n",
      "L= 14 p= 0.516 data_size: 10000 10000\n",
      "L= 14 p= 0.583 data_size: 10000 10000\n",
      "L= 14 p= 0.651 data_size: 10000 10000\n",
      "L= 14 p= 0.718 data_size: 10000 10000\n",
      "L= 14 p= 0.785 data_size: 10000 10000\n",
      "L= 14 p= 0.853 data_size: 10000 10000\n",
      "L= 14 p= 0.92 data_size: 10000 10000\n",
      "L= 14 p= 0.987 data_size: 10000 10000\n",
      "L= 14 p= 1.055 data_size: 10000 10000\n",
      "L= 14 p= 1.122 data_size: 10000 10000\n",
      "L= 14 p= 1.189 data_size: 10000 10000\n",
      "L= 14 p= 1.257 data_size: 10000 10000\n"
     ]
    }
   ],
   "source": [
    "L_list = [6,8,10,12,14,16][:5]\n",
    "\n",
    "colors = pl.cm.Blues(np.linspace(0.5,1,len(L_list)))\n",
    "\n",
    "depth_ratio=0.5\n",
    "if depth_ratio != 1:\n",
    "    depth_label = '_depth_ratio='+str(depth_ratio) + '/'\n",
    "else:\n",
    "    depth_label = '/'\n",
    "\n",
    "fig,axs = pl.subplots(1,2,figsize=(11,5))\n",
    "\n",
    "\n",
    "    \n",
    "ROOT_DIREC = 'data/'\n",
    "# p_select = np.array([0.07853981633974483,0.23561944901923448 ,0.516,0.785,0.92,1.122])\n",
    "is_noisy = ''\n",
    "# decoding_label_3 = '_decoding_protocol='+str(3)\n",
    "decoding_label_0 = '_decoding_protocol='+str(0)\n",
    "\n",
    "file_large = 'large_scale_data/biased_sep_seed=1_all_qubits_special_scrambled'\n",
    "\n",
    "file_large = 'large_scale_data/quantum_decoder_seed=1_all_qubits_special_scrambled'\n",
    "\n",
    "\n",
    "      \n",
    "\n",
    "\n",
    "\n",
    "RNN = False\n",
    "lw = 3\n",
    "ms=6 \n",
    "if not RNN:\n",
    "    data2 = load_data(file_large)\n",
    "\n",
    "    suc_prob_sim, err_sim, var_sim, var_err_sim = get_ancilla_data(data2,L_list,temp_quan=0,p_selected=[])\n",
    "    for i,L in enumerate(L_list):\n",
    "        p_data_sim = np.array(sorted(list(suc_prob_sim[L].keys())))\n",
    "        ydata_sim = np.array([suc_prob_sim[L][p] for p in p_data_sim])\n",
    "        errdata_sim = [err_sim[L][p] for p in p_data_sim]\n",
    "        var_ydata_sim = [var_sim[L][p] for p in p_data_sim]\n",
    "        var_errdata_sim = [var_err_sim[L][p] for p in p_data_sim]\n",
    "\n",
    "\n",
    "        axs[0].errorbar((p_data_sim/(np.pi/2)-0.457)*L**(3/4),ydata_sim*L**(1),yerr=errdata_sim,marker='o',ls='-',color=colors[i],ms=ms,alpha=1,lw=lw,label=r'$L={}$'.format(L))\n",
    "\n",
    "\n",
    "        axs[1].errorbar(p_data_sim/(np.pi/2),var_ydata_sim,yerr=var_errdata_sim,marker='o',ls='-',color=colors[i],ms=ms,alpha=1,lw=lw)\n",
    "\n",
    "\n",
    "if RNN:\n",
    "    for i,L in enumerate(L_list):\n",
    "        p_data_sim,ydata_sim,var_ydata_sim = get_RNN_simulation_data_suc_prob(L,sorted(p_select))\n",
    "        p_data_sim = np.array(p_data_sim)\n",
    "        axs[0].plot(p_data_sim/(np.pi/2),ydata_sim,marker='o',ls='-',color=colors[i],ms=ms,alpha=1,lw=lw,label=r'$L={}$'.format(L))\n",
    "\n",
    "\n",
    "        axs[1].plot(p_data_sim/(np.pi/2),var_ydata_sim,marker='o',ls='-',color=colors[i],ms=ms,alpha=1,lw=lw)\n",
    "\n",
    "# [pl.plot([],[],'-',label=r'$L=$'+str(L)) for L in L_list]\n",
    "\n",
    "axs[0].tick_params(axis='both', which='major', labelsize=14)\n",
    "axs[1].tick_params(axis='both', which='major', labelsize=14)\n",
    "\n",
    "label_size = 16\n",
    "\n",
    "axs[0].set_ylabel(r'$S_R$',fontsize=label_size+2)\n",
    "axs[1].set_ylabel(r'Variance of $S_R$',fontsize=label_size)\n",
    "\n",
    "axs[0].set_xlabel(r'$\\gamma$',fontsize=label_size)\n",
    "axs[1].set_xlabel(r'$\\gamma$',fontsize=label_size)\n",
    "\n",
    "axs[0].legend(fontsize=12)\n",
    "\n",
    "fig.set_tight_layout(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binder ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L= 6 p= 0.07853981633974483 data_size: 10000 10000\n",
      "L= 6 p= 0.15707963267948966 data_size: 10000 10000\n",
      "L= 6 p= 0.23561944901923448 data_size: 10000 10000\n",
      "L= 6 p= 0.314 data_size: 10000 10000\n",
      "L= 6 p= 0.381 data_size: 10000 10000\n",
      "L= 6 p= 0.449 data_size: 10000 10000\n",
      "L= 6 p= 0.516 data_size: 10000 10000\n",
      "L= 6 p= 0.583 data_size: 10000 10000\n",
      "L= 6 p= 0.651 data_size: 10000 10000\n",
      "L= 6 p= 0.718 data_size: 10000 10000\n",
      "L= 6 p= 0.785 data_size: 10000 10000\n",
      "L= 6 p= 0.853 data_size: 10000 10000\n",
      "L= 6 p= 0.92 data_size: 10000 10000\n",
      "L= 6 p= 0.987 data_size: 10000 10000\n",
      "L= 6 p= 1.055 data_size: 10000 10000\n",
      "L= 6 p= 1.122 data_size: 10000 10000\n",
      "L= 6 p= 1.189 data_size: 10000 10000\n",
      "L= 6 p= 1.257 data_size: 10000 10000\n",
      "L= 8 p= 0.07853981633974483 data_size: 10000 10000\n",
      "L= 8 p= 0.15707963267948966 data_size: 10000 10000\n",
      "L= 8 p= 0.23561944901923448 data_size: 10000 10000\n",
      "L= 8 p= 0.314 data_size: 10000 10000\n",
      "L= 8 p= 0.381 data_size: 10000 10000\n",
      "L= 8 p= 0.449 data_size: 10000 10000\n",
      "L= 8 p= 0.516 data_size: 10000 10000\n",
      "L= 8 p= 0.583 data_size: 10000 10000\n",
      "L= 8 p= 0.651 data_size: 10000 10000\n",
      "L= 8 p= 0.718 data_size: 10000 10000\n",
      "L= 8 p= 0.785 data_size: 10000 10000\n",
      "L= 8 p= 0.853 data_size: 10000 10000\n",
      "L= 8 p= 0.92 data_size: 10000 10000\n",
      "L= 8 p= 0.987 data_size: 10000 10000\n",
      "L= 8 p= 1.055 data_size: 10000 10000\n",
      "L= 8 p= 1.122 data_size: 10000 10000\n",
      "L= 8 p= 1.189 data_size: 10000 10000\n",
      "L= 8 p= 1.257 data_size: 10000 10000\n",
      "L= 10 p= 0.07853981633974483 data_size: 10000 10000\n",
      "L= 10 p= 0.15707963267948966 data_size: 10000 10000\n",
      "L= 10 p= 0.23561944901923448 data_size: 10000 10000\n",
      "L= 10 p= 0.314 data_size: 10000 10000\n",
      "L= 10 p= 0.381 data_size: 10000 10000\n",
      "L= 10 p= 0.449 data_size: 10000 10000\n",
      "L= 10 p= 0.516 data_size: 10000 10000\n",
      "L= 10 p= 0.583 data_size: 10000 10000\n",
      "L= 10 p= 0.651 data_size: 10000 10000\n",
      "L= 10 p= 0.718 data_size: 10000 10000\n",
      "L= 10 p= 0.785 data_size: 10000 10000\n",
      "L= 10 p= 0.853 data_size: 10000 10000\n",
      "L= 10 p= 0.92 data_size: 10000 10000\n",
      "L= 10 p= 0.987 data_size: 10000 10000\n",
      "L= 10 p= 1.055 data_size: 10000 10000\n",
      "L= 10 p= 1.122 data_size: 10000 10000\n",
      "L= 10 p= 1.189 data_size: 10000 10000\n",
      "L= 10 p= 1.257 data_size: 10000 10000\n",
      "L= 12 p= 0.07853981633974483 data_size: 10000 10000\n",
      "L= 12 p= 0.15707963267948966 data_size: 10000 10000\n",
      "L= 12 p= 0.23561944901923448 data_size: 10000 10000\n",
      "L= 12 p= 0.314 data_size: 10000 10000\n",
      "L= 12 p= 0.381 data_size: 10000 10000\n",
      "L= 12 p= 0.449 data_size: 10000 10000\n",
      "L= 12 p= 0.516 data_size: 10000 10000\n",
      "L= 12 p= 0.583 data_size: 10000 10000\n",
      "L= 12 p= 0.651 data_size: 10000 10000\n",
      "L= 12 p= 0.718 data_size: 10000 10000\n",
      "L= 12 p= 0.785 data_size: 10000 10000\n",
      "L= 12 p= 0.853 data_size: 10000 10000\n",
      "L= 12 p= 0.92 data_size: 10000 10000\n",
      "L= 12 p= 0.987 data_size: 10000 10000\n",
      "L= 12 p= 1.055 data_size: 10000 10000\n",
      "L= 12 p= 1.122 data_size: 10000 10000\n",
      "L= 12 p= 1.189 data_size: 10000 10000\n",
      "L= 12 p= 1.257 data_size: 10000 10000\n",
      "L= 14 p= 0.07853981633974483 data_size: 10000 10000\n",
      "L= 14 p= 0.15707963267948966 data_size: 10000 10000\n",
      "L= 14 p= 0.23561944901923448 data_size: 10000 10000\n",
      "L= 14 p= 0.314 data_size: 10000 10000\n",
      "L= 14 p= 0.381 data_size: 10000 10000\n",
      "L= 14 p= 0.449 data_size: 10000 10000\n",
      "L= 14 p= 0.516 data_size: 10000 10000\n",
      "L= 14 p= 0.583 data_size: 10000 10000\n",
      "L= 14 p= 0.651 data_size: 10000 10000\n",
      "L= 14 p= 0.718 data_size: 10000 10000\n",
      "L= 14 p= 0.785 data_size: 10000 10000\n",
      "L= 14 p= 0.853 data_size: 10000 10000\n",
      "L= 14 p= 0.92 data_size: 10000 10000\n",
      "L= 14 p= 0.987 data_size: 10000 10000\n",
      "L= 14 p= 1.055 data_size: 10000 10000\n",
      "L= 14 p= 1.122 data_size: 10000 10000\n",
      "L= 14 p= 1.189 data_size: 10000 10000\n",
      "L= 14 p= 1.257 data_size: 10000 10000\n"
     ]
    }
   ],
   "source": [
    "L_list = [6,8,10,12,14,16][:5]\n",
    "\n",
    "colors = pl.cm.Blues(np.linspace(0.5,1,len(L_list)))\n",
    "\n",
    "depth_ratio=0.5\n",
    "if depth_ratio != 1:\n",
    "    depth_label = '_depth_ratio='+str(depth_ratio) + '/'\n",
    "else:\n",
    "    depth_label = '/'\n",
    "\n",
    "fig,axs = pl.subplots(1,1,figsize=(6,5))\n",
    "\n",
    "    \n",
    "ROOT_DIREC = 'data/'\n",
    "# p_select = np.array([0.07853981633974483,0.23561944901923448 ,0.516,0.785,0.92,1.122])\n",
    "is_noisy = ''\n",
    "# decoding_label_3 = '_decoding_protocol='+str(3)\n",
    "decoding_label_0 = '_decoding_protocol='+str(0)\n",
    "\n",
    "file_large = 'large_scale_data/biased_sep_seed=1_all_qubits_special_scrambled'\n",
    "\n",
    "file_large = 'large_scale_data/quantum_decoder_seed=1_all_qubits_special_scrambled'\n",
    "\n",
    "lw = 2\n",
    "ms=6 \n",
    "if not RNN:\n",
    "    data2 = load_data(file_large)\n",
    "\n",
    "    binder = get_binder_data(data2,L_list,temp_quan=0,p_selected=[])\n",
    "    for i,L in enumerate(L_list):\n",
    "        p_data_sim = np.array(sorted(list(suc_prob_sim[L].keys())))\n",
    "        ydata_sim = [binder[L][p] for p in p_data_sim]\n",
    "        \n",
    "        axs.plot(p_data_sim/(np.pi/2),ydata_sim,marker='o',ls='-',color=colors[i],ms=ms,alpha=1,lw=lw,label=r'$L={}$'.format(L))\n",
    "\n",
    "\n",
    "axs.tick_params(axis='both', which='major', labelsize=14)\n",
    "\n",
    "label_size = 16\n",
    "\n",
    "axs.set_ylabel(r'Binder ratio',fontsize=label_size+2)\n",
    "\n",
    "axs.set_xlabel(r'$\\gamma$',fontsize=label_size)\n",
    "\n",
    "axs.legend(fontsize=12)\n",
    "\n",
    "# axs.set_ylim(-10,0.5)\n",
    "fig.set_tight_layout(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../Quantinum/Weak measurements/emulator_data/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/utkarshagrawal/Documents/Postdoc/U_1_exp/Weak measurements/analyze_data copy.ipynb Cell 14\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/utkarshagrawal/Documents/Postdoc/U_1_exp/Weak%20measurements/analyze_data%20copy.ipynb#X43sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m os\u001b[39m.\u001b[39;49mlistdir(\u001b[39m'\u001b[39;49m\u001b[39m../Quantinum/Weak measurements/emulator_data/\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../Quantinum/Weak measurements/emulator_data/'"
     ]
    }
   ],
   "source": [
    "os.listdir('../Quantinum/Weak measurements/emulator_data/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure for proposal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pl' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/utkarshagrawal/Documents/Postdoc/U_1_exp/Weak measurements/analyze_data copy.ipynb Cell 18\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/utkarshagrawal/Documents/Postdoc/U_1_exp/Weak%20measurements/analyze_data%20copy.ipynb#X23sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# %matplotlib qt\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/utkarshagrawal/Documents/Postdoc/U_1_exp/Weak%20measurements/analyze_data%20copy.ipynb#X23sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m pl\u001b[39m.\u001b[39mfigure(\u001b[39m1\u001b[39m,figsize\u001b[39m=\u001b[39m(\u001b[39m16\u001b[39m,\u001b[39m5\u001b[39m))\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/utkarshagrawal/Documents/Postdoc/U_1_exp/Weak%20measurements/analyze_data%20copy.ipynb#X23sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m L_list \u001b[39m=\u001b[39m [\u001b[39m6\u001b[39m,\u001b[39m8\u001b[39m,\u001b[39m10\u001b[39m,\u001b[39m12\u001b[39m,\u001b[39m16\u001b[39m][:\u001b[39m4\u001b[39m][:\u001b[39m4\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/utkarshagrawal/Documents/Postdoc/U_1_exp/Weak%20measurements/analyze_data%20copy.ipynb#X23sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m pl\u001b[39m.\u001b[39msuptitle(\u001b[39m'\u001b[39m\u001b[39mQiskit data\u001b[39m\u001b[39m'\u001b[39m,fontsize\u001b[39m=\u001b[39m\u001b[39m20\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pl' is not defined"
     ]
    }
   ],
   "source": [
    "# %matplotlib qt\n",
    "pl.figure(1,figsize=(16,5))\n",
    "L_list = [6,8,10,12,16][:4][:4]\n",
    "pl.suptitle('Qiskit data',fontsize=20)\n",
    "file = 'data_quantum_decoder/decoder/seed=1_all_qubits_special_scrambled_decoding_protocol='\n",
    "\n",
    "file2 = 'data/sep_data/seed=1_all_qubits_special_scrambled_decoding_protocol='\n",
    "prop_cycle = pl.rcParams['axes.prop_cycle']\n",
    "colors = prop_cycle.by_key()['color'][:]\n",
    "\n",
    "protocols = [-1,0,3]\n",
    "\n",
    "\n",
    "\n",
    "for i,decoding_protocol in enumerate(protocols):\n",
    "    pl.subplot(1,3,i+1)\n",
    "    if i==0:\n",
    "        pl.ylabel(r'Success prob',fontsize=16)\n",
    "\n",
    "    if decoding_protocol == -1:\n",
    "        is_noisy = ''\n",
    "        decoding_protocol = 0\n",
    "        noisy_label = 'No noise'\n",
    "    else:\n",
    "        is_noisy = '_noisy'\n",
    "        noisy_label = 'Noisy'\n",
    "    \n",
    "    if decoding_protocol == 0:\n",
    "        decoding_label = 'No mitigation'\n",
    "    elif decoding_protocol == 3:\n",
    "        decoding_label = 'Error mitigated'\n",
    "    # data=load_data(file+str(decoding_protocol)+is_noisy)\n",
    "    data2 = load_data(file2+str(decoding_protocol)+is_noisy)\n",
    "    print(data.keys())\n",
    "    N_samples = 300\n",
    "    plot_success_prob(data,L_list,charge_fac=0,marker='s',N_samples=N_samples,color_list=colors)\n",
    "    plot_success_prob(data2,L_list,charge_fac=0,marker='s',ls='--',N_samples=N_samples,color_list=colors,temp_quan=0,post_label='_SEP')\n",
    "\n",
    "    # plot_success_binder(data,L_list,marker='s',N_samples=-1)\n",
    "    pl.title(noisy_label+'. '+ decoding_label + '. ' + 'shots = {}'.format(N_samples),fontsize=16)\n",
    "    pl.tight_layout()\n",
    "    pl.ylim(0.45,1.05)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Cannot change to a different GUI toolkit: qt. Using qt5 instead.\n",
      "L= 6 p= 0.412 data_size: 299 299\n",
      "L= 6 p= 0.518 data_size: 299 299\n",
      "L= 6 p= 0.624 data_size: 299 299\n",
      "L= 6 p= 0.73 data_size: 299 299\n",
      "L= 6 p= 0.836 data_size: 299 299\n",
      "L= 10 p= 0.412 data_size: 299 299\n",
      "L= 10 p= 0.518 data_size: 299 299\n",
      "L= 10 p= 0.624 data_size: 299 299\n",
      "L= 10 p= 0.73 data_size: 299 299\n",
      "L= 10 p= 0.836 data_size: 299 299\n",
      "L= 14 p= 0.412 data_size: 299 299\n",
      "L= 14 p= 0.518 data_size: 299 299\n",
      "L= 14 p= 0.624 data_size: 299 299\n",
      "L= 14 p= 0.73 data_size: 299 299\n",
      "L= 14 p= 0.836 data_size: 299 299\n",
      "L= 6 p= 0.412 data_size: 299 299\n",
      "L= 6 p= 0.518 data_size: 299 299\n",
      "L= 6 p= 0.624 data_size: 299 299\n",
      "L= 6 p= 0.73 data_size: 299 299\n",
      "L= 6 p= 0.836 data_size: 299 299\n",
      "L= 8 p= 0.412 data_size: 299 299\n",
      "L= 8 p= 0.518 data_size: 299 299\n",
      "L= 8 p= 0.624 data_size: 299 299\n",
      "L= 8 p= 0.73 data_size: 299 299\n",
      "L= 8 p= 0.836 data_size: 299 299\n",
      "L= 10 p= 0.412 data_size: 299 299\n",
      "L= 10 p= 0.518 data_size: 299 299\n",
      "L= 10 p= 0.624 data_size: 299 299\n",
      "L= 10 p= 0.73 data_size: 299 299\n",
      "L= 10 p= 0.836 data_size: 299 299\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.2, 0.5)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib qt\n",
    "pl.figure(1)\n",
    "\n",
    "data=load_data('data/biased_sep_data/seed=1_all_qubits_special_scrambled')\n",
    "L_list = [6,8,10,12,14,16][::2]\n",
    "plot_success_ent(data,L_list,charge_fac=0,marker='s')\n",
    "# plot_success_binder(data,L_list,marker='s',N_samples=-1)\n",
    "pl.title('Biased decoder. Not Noisy, N_samples = 600',fontsize=16)\n",
    "pl.tight_layout()\n",
    "pl.xlim(0.2,0.5)\n",
    "# pl.ylim(-2,1)\n",
    "\n",
    "\n",
    "pl.figure(2)\n",
    "# pl.ylim(0,np.log(2))\n",
    "data=load_data('data/biased_sep_data/seed=1_all_qubits_special_scrambled')\n",
    "L_list = [6,8,10,12,14,16][:3]\n",
    "plot_success_ent(data,L_list,charge_fac=0,marker='s')\n",
    "# plot_success_binder(data,L_list,marker='s',N_samples=-1)\n",
    "pl.title('Biased decoder. Noisy, N_samples = 600',fontsize=16)\n",
    "pl.tight_layout()\n",
    "pl.xlim(0.2,0.5)\n",
    "# pl.ylim(-2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L= 6 p= 0.2 data_size: 300 300\n",
      "L= 6 p= 0.253 data_size: 300 300\n",
      "L= 6 p= 0.306 data_size: 300 300\n",
      "L= 6 p= 0.359 data_size: 300 300\n",
      "L= 6 p= 0.412 data_size: 300 300\n",
      "L= 6 p= 0.465 data_size: 300 300\n",
      "L= 6 p= 0.518 data_size: 300 300\n",
      "L= 6 p= 0.571 data_size: 300 300\n",
      "L= 6 p= 0.624 data_size: 300 300\n",
      "L= 6 p= 0.677 data_size: 300 300\n",
      "L= 6 p= 0.73 data_size: 300 300\n",
      "L= 6 p= 0.783 data_size: 300 300\n",
      "L= 6 p= 0.836 data_size: 300 300\n",
      "L= 6 p= 0.889 data_size: 300 300\n",
      "L= 6 p= 0.942 data_size: 300 300\n",
      "L= 6 p= 0.2 data_size: 45 45\n",
      "L= 6 p= 0.253 data_size: 45 45\n",
      "L= 6 p= 0.306 data_size: 45 45\n",
      "L= 6 p= 0.359 data_size: 45 45\n",
      "L= 6 p= 0.412 data_size: 45 45\n",
      "L= 6 p= 0.465 data_size: 45 45\n",
      "L= 6 p= 0.518 data_size: 45 45\n",
      "L= 6 p= 0.571 data_size: 45 45\n",
      "L= 6 p= 0.624 data_size: 45 45\n",
      "L= 6 p= 0.677 data_size: 45 45\n",
      "L= 6 p= 0.73 data_size: 45 45\n",
      "L= 6 p= 0.783 data_size: 45 45\n",
      "L= 6 p= 0.836 data_size: 45 45\n",
      "L= 6 p= 0.889 data_size: 45 45\n",
      "L= 6 p= 0.942 data_size: 45 45\n"
     ]
    }
   ],
   "source": [
    "%matplotlib qt\n",
    "pl.figure(1)\n",
    "\n",
    "data=load_data('data/sep_data/seed=1_all_qubits_special_scrambled')\n",
    "L_list = [6,8,10,12,14,16][:1]\n",
    "plot_success_ent(data,L_list,charge_fac=0,marker='s',N_samples=300)\n",
    "# pl.ylim(0,np.log(2))\n",
    "pl.title('Not noisy, N_samples = 300',fontsize=16)\n",
    "pl.tight_layout()\n",
    "\n",
    "pl.figure(2)\n",
    "# pl.ylim(0,np.log(2))\n",
    "data=load_data('data/sep_data/seed=1_all_qubits_special_scrambled_noisy')\n",
    "L_list = [6,8,10,12,14,16][:1]\n",
    "plot_success_ent(data,L_list,charge_fac=0,marker='s',N_samples=45)\n",
    "pl.title('Noisy, N_samples = 50',fontsize=16)\n",
    "pl.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to ensure that p_suc for initial states with charge Q has non-zero probabilities\n",
    "def sanity_check(data,L_list,p_list):\n",
    "    for L in L_list[:]:\n",
    "        for p in p_list:\n",
    "            p_Q = list(data[L][p][L//2])\n",
    "            p_Q2 = list(data[L][p][L//2-1])\n",
    "            if np.any(p_Q==0) or np.any(p_Q2==0):\n",
    "                print(\"There are some zero probabilities\")\n",
    "            else:\n",
    "                print(\"L =\",L,\"p =\",p,\"Sanity check complete; no zero probabilities\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L = 8 p = 0.05 Sanity check complete; no zero probabilities\n",
      "L = 8 p = 0.1 Sanity check complete; no zero probabilities\n",
      "L = 8 p = 0.13 Sanity check complete; no zero probabilities\n",
      "L = 8 p = 0.16 Sanity check complete; no zero probabilities\n",
      "L = 8 p = 0.2 Sanity check complete; no zero probabilities\n",
      "L = 8 p = 0.25 Sanity check complete; no zero probabilities\n",
      "L = 8 p = 0.3 Sanity check complete; no zero probabilities\n",
      "L = 10 p = 0.05 Sanity check complete; no zero probabilities\n",
      "L = 10 p = 0.1 Sanity check complete; no zero probabilities\n",
      "L = 10 p = 0.13 Sanity check complete; no zero probabilities\n",
      "L = 10 p = 0.16 Sanity check complete; no zero probabilities\n",
      "L = 10 p = 0.2 Sanity check complete; no zero probabilities\n",
      "L = 10 p = 0.25 Sanity check complete; no zero probabilities\n",
      "L = 10 p = 0.3 Sanity check complete; no zero probabilities\n",
      "L = 12 p = 0.05 Sanity check complete; no zero probabilities\n",
      "L = 12 p = 0.1 Sanity check complete; no zero probabilities\n",
      "L = 12 p = 0.13 Sanity check complete; no zero probabilities\n",
      "L = 12 p = 0.16 Sanity check complete; no zero probabilities\n",
      "L = 12 p = 0.2 Sanity check complete; no zero probabilities\n",
      "L = 12 p = 0.25 Sanity check complete; no zero probabilities\n",
      "L = 12 p = 0.3 Sanity check complete; no zero probabilities\n"
     ]
    }
   ],
   "source": [
    "sanity_check(data,L_list,p_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = np.eye(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(6):\n",
    "    aa[i,(3+i)%6]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa[[3,4,5],[3,4,5]]=-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa=aa/2**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b = np.linalg.eig(aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.65328148,  0.        ,  0.        ,  0.27059805,  0.        ,\n",
       "         0.        ],\n",
       "       [ 0.27059805,  0.        ,  0.        , -0.65328148,  0.        ,\n",
       "         0.        ],\n",
       "       [ 0.        ,  0.        ,  0.65328148,  0.        ,  0.        ,\n",
       "         0.27059805],\n",
       "       [ 0.        ,  0.        ,  0.27059805,  0.        ,  0.        ,\n",
       "        -0.65328148],\n",
       "       [ 0.        ,  0.27059805,  0.        ,  0.        , -0.65328148,\n",
       "         0.        ],\n",
       "       [ 0.        , -0.65328148,  0.        ,  0.        , -0.27059805,\n",
       "         0.        ]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.T/2**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 1., -1.,  1., -1., -1.,  1.]),\n",
       " array([[ 0.92387953,  0.        ,  0.        ,  0.38268343,  0.        ,\n",
       "          0.        ],\n",
       "        [ 0.38268343,  0.        ,  0.        , -0.92387953,  0.        ,\n",
       "          0.        ],\n",
       "        [ 0.        ,  0.        ,  0.92387953,  0.        ,  0.        ,\n",
       "          0.38268343],\n",
       "        [ 0.        ,  0.        ,  0.38268343,  0.        ,  0.        ,\n",
       "         -0.92387953],\n",
       "        [ 0.        ,  0.38268343,  0.        ,  0.        , -0.92387953,\n",
       "          0.        ],\n",
       "        [ 0.        , -0.92387953,  0.        ,  0.        , -0.38268343,\n",
       "          0.        ]]))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a,b.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8535533859530209"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.92387953**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.31622776601683794"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/10**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../quantum_decoder_seed=1_all_qubits_special_scrambled\",'rb') as f:\n",
    "    data = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([6, 8, 10, 12])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "qt.qpa.backingstore: Back buffer dpr of 1 doesn't match <_NSViewBackingLayer: 0x2d0026da0> contents scale of 2 - updating layer to match.\n",
      "qt.qpa.backingstore: Back buffer dpr of 2 doesn't match <_NSViewBackingLayer: 0x2d0026da0> contents scale of 1 - updating layer to match.\n",
      "qt.qpa.backingstore: Back buffer dpr of 2 doesn't match <_NSViewBackingLayer: 0x2d0026da0> contents scale of 1 - updating layer to match.\n",
      "qt.qpa.backingstore: Back buffer dpr of 1 doesn't match <_NSViewBackingLayer: 0x2d0026da0> contents scale of 2 - updating layer to match.\n",
      "qt.qpa.backingstore: Back buffer dpr of 1 doesn't match <_NSViewBackingLayer: 0x2d0026da0> contents scale of 2 - updating layer to match.\n",
      "qt.qpa.backingstore: Back buffer dpr of 2 doesn't match <_NSViewBackingLayer: 0x2d0026da0> contents scale of 1 - updating layer to match.\n",
      "qt.qpa.backingstore: Back buffer dpr of 2 doesn't match <_NSViewBackingLayer: 0x2d0026da0> contents scale of 1 - updating layer to match.\n",
      "qt.qpa.backingstore: Back buffer dpr of 1 doesn't match <_NSViewBackingLayer: 0x2d0026da0> contents scale of 2 - updating layer to match.\n",
      "qt.qpa.backingstore: Back buffer dpr of 1 doesn't match <_NSViewBackingLayer: 0x2d0026da0> contents scale of 2 - updating layer to match.\n",
      "qt.qpa.backingstore: Back buffer dpr of 2 doesn't match <_NSViewBackingLayer: 0x2d0026da0> contents scale of 1 - updating layer to match.\n",
      "qt.qpa.backingstore: Back buffer dpr of 1 doesn't match <_NSViewBackingLayer: 0x2d0026da0> contents scale of 2 - updating layer to match.\n",
      "qt.qpa.backingstore: Back buffer dpr of 1 doesn't match <_NSViewBackingLayer: 0x2d0026da0> contents scale of 2 - updating layer to match.\n",
      "qt.qpa.backingstore: Back buffer dpr of 2 doesn't match <_NSViewBackingLayer: 0x2d0026da0> contents scale of 1 - updating layer to match.\n"
     ]
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/post_selected_traj_BIASED','rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
       "        [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
       "        [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
       "        [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
       "        [-1, -1, -1, -1,  1, -1,  1,  1,  1,  1]]),\n",
       " 1)"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(data[(10, 0.236, 5)])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "46d4d6e35a705a453addec98352089b1c875d6193677971858623155cb10eb88"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
